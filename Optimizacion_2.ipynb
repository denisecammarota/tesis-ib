{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras.callbacks import History \n",
    "#using tensorflow backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_cases_per_day(fecha_sintomas,graph=False,ret=False):\n",
    "    \"\"\"\n",
    "    args: \n",
    "    -fecha_sintomas: day of beginning of symptomps for each case, can't be NaN or NaT (already processed)\n",
    "    -graph: defaults to False. if True, makes graph of new cases per day \n",
    "    -ret: defaults to False. if True, returns days-cases per day  np.array casos_por_dia\n",
    "    given the days of beginning of symptoms, processes to get np.array of cases per day and days since epidemic\n",
    "    can graph and return this vector with the defaults explained before\n",
    "    \"\"\"\n",
    "    counts = np.bincount(fecha_sintomas)\n",
    "    ultima_fecha = max(fecha_sintomas)\n",
    "    aux = range(ultima_fecha+1)\n",
    "    casos_por_dia = np.vstack((aux,counts[aux])).T #(days since inicio_epidemia x (fecha_inicio_sintomas == days))\n",
    "    if graph == True:\n",
    "        plt.xlabel(\"Dia\")\n",
    "        plt.ylabel(\"Casos\")\n",
    "        plt.axvspan(ultima_fecha-10, ultima_fecha+3, facecolor='r', alpha=0.5,label=\"últimos 10 días\")\n",
    "        plt.plot(casos_por_dia[:,0],casos_por_dia[:,1],'-ob',label=\"casos hasta dia: \"+str(ultima_fecha))\n",
    "        plt.style.use('ggplot')\n",
    "        plt.legend()\n",
    "        #plt.savefig(\"casos_por_dia_bariloche.pdf\")\n",
    "    if ret == True:\n",
    "        return casos_por_dia   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulative_cases(fecha_sintomas,graph=False,ret=False):\n",
    "    \"\"\"\n",
    "    args: \n",
    "    -fecha_sintomas: day of beginning of symptomps for each case, can't be NaN or NaT (already processed)\n",
    "    -graph: defaults to False. if True, makes graph of new cases per day \n",
    "    -ret: defaults to False. if True, returns days-cumulative cases per day np array\n",
    "    given the days of beginning of symptoms, processes to get np.array of cumulative cases per day and days since epidemic\n",
    "    can graph and return this vector with the defaults explained before\n",
    "    \"\"\"\n",
    "    ultima_fecha = max(fecha_sintomas)\n",
    "    casos_por_dia = new_cases_per_day(fecha_sintomas,ret=True)\n",
    "    casos_acumulados_por_dia = np.copy(casos_por_dia)\n",
    "    casos_acumulados_por_dia[:,1] = np.cumsum(casos_por_dia[:,1]) \n",
    "    if graph == True:\n",
    "        plt.xlabel(\"Dia\")\n",
    "        plt.ylabel(\"Casos acumulados\")\n",
    "        plt.axvspan(ultima_fecha-10, ultima_fecha+3, facecolor='r', alpha=0.5,label=\"últimos 10 días\")\n",
    "        plt.scatter(casos_acumulados_por_dia[:,0],casos_acumulados_por_dia[:,1],c='b',label=\"casos acumulados hasta dia: \"+str(ultima_fecha))\n",
    "        plt.legend()\n",
    "        plt.style.use('ggplot')\n",
    "        plt.savefig(\"casos_acumulados_bariloche.pdf\")\n",
    "    if ret == True:\n",
    "        return casos_acumulados_por_dia   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repratio_t_conv(fecha_sintomas,a,graph=False,ret=False):\n",
    "    \"\"\"\n",
    "    args: \n",
    "    -fecha_sintomas: day of beginning of symptomps for each case, can't be NaN or NaT (already processed)\n",
    "    -graph: defaults to False. if True, makes graph of rep ratio per day\n",
    "    -ret: defaults to False. if True, returns reproductive ratio per day np array of (days,r_days) and\n",
    "    the n_t vector which is used to calculate it, which is extension of new cases per day made as \n",
    "    necessary, by taking means and not linear regression. \n",
    "    given the days of beginning of symptoms, processes to get np.array of cumulative cases per day and days since epidemic\n",
    "    can graph and return this vector with the defaults explained before for days (0,lastday+4)\n",
    "    conventional version, which means no coef a,b,c,d,e. r_t valid for days >= 6. \n",
    "    \"\"\"\n",
    "    casos_por_dia = new_cases_per_day(fecha_sintomas,ret=True)\n",
    "    n_t = np.copy(casos_por_dia) #here we store data + proyection for days t+4 \n",
    "    prox_dia = max(fecha_sintomas) + 1\n",
    "    #completing the values for the rest of the values of n_t\n",
    "    aux = np.zeros(2)\n",
    "    i = 0\n",
    "    while i < 4: #completing until the day t+4 bc im gonna need it later for averaging in 7 days\n",
    "        aux[0] = prox_dia + i\n",
    "        aux[1] = np.mean(n_t[prox_dia-7:,1])\n",
    "        n_t  = np.vstack((n_t,aux)) #extending n_t up to day t+1\n",
    "        i= i +1\n",
    "    #create storage and calculate values for r_t\n",
    "    r_t = np.copy(n_t) #here we will store the rt\n",
    "    r_t = r_t.astype(float)\n",
    "    dias_aux = np.arange(0,prox_dia+3)\n",
    "    for i in dias_aux[dias_aux>=6]:\n",
    "        aux = a[0]*n_t[i-6,1] + a[1]*n_t[i-5,1] + a[2]*n_t[i-4,1] #denominator of the r_t expression\n",
    "        if(aux==0):\n",
    "            aux = 1 #the first cases in which the denominator is == 0\n",
    "        r_t[i,1] = min(((a[3]*n_t[i-1,1] + a[4]*n_t[i,1] + a[5]*n_t[i+1,1])/(aux)),4) #the rest of the days with limit value\n",
    "    if graph == True:\n",
    "        plt.style.use('ggplot')\n",
    "        plt.axvspan(prox_dia-10, prox_dia+3, facecolor='r', alpha=0.5,label=\"últimos 10 días\")\n",
    "        plt.scatter(r_t[6:prox_dia,0],r_t[6:prox_dia,1],c='b',label=r'$r_t$')\n",
    "        plt.xlabel(\"Dia\")\n",
    "        plt.ylabel(r'$r_t$',fontsize=12)\n",
    "        plt.legend()\n",
    "        plt.savefig(\"rt_raw_casos.pdf\")\n",
    "    if ret == True:\n",
    "        return n_t,r_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk_diagram(fecha_sintomas,pop,a,rep_fun=repratio_t_conv,graph=False,ret=False):\n",
    "    \"\"\"\n",
    "    args: \n",
    "    -fecha_sintomas: day of beginning of symptomps for each case, can't be NaN or NaT (already processed)\n",
    "    -pop: number of inhabitants of the region/population of interest\n",
    "    -rep_fun: function to calculate empirical reproductive ratio. defaults tp repratio_t_conv (not optimized)\n",
    "    -graph: defaults to False. if True, makes graph of risk diagram\n",
    "    -ret: defaults to False. if True, returns the components of risk diagram in two np.arrays, which are\n",
    "     the attack ratio (days>=20) as well as the rep ratio averaged over 7 days (days>=20). \n",
    "    \"\"\"\n",
    "    #we proceed to calculate what makes a risk diagram then\n",
    "    #first, we will calculate r_t average in 7 days\n",
    "    prox_dia = max(fecha_sintomas) + 1\n",
    "    n_t,r_t = rep_fun(fecha_sintomas,a,False,True)\n",
    "    r_t_seven = np.zeros(prox_dia) #real values for index>=9\n",
    "    a_t = np.zeros(prox_dia) #real values for index >= 13\n",
    "    i = 9\n",
    "    while i < prox_dia:\n",
    "        r_t_seven[i] = np.mean(r_t[i-3:i+4,1])\n",
    "        i = i+1\n",
    "    i = 13\n",
    "    while i < prox_dia:\n",
    "        a_t[i] = np.sum(n_t[i-13:i+1,1]) \n",
    "        i = i+1\n",
    "    a_t = a_t * (100000/pop)\n",
    "    if graph == True:\n",
    "        plt.plot(a_t[13:],r_t_seven[13:],'-or',markersize=5) #not at all fancy risk diagram,looks reasonable\n",
    "        plt.xlabel(r'$A_{t}^{14}$')\n",
    "        plt.ylabel(r'$R_{t}^{7}$')\n",
    "        plt.style.use('ggplot')\n",
    "        plt.title('Diagrama de riesgo Bariloche',fontsize=10)\n",
    "        plt.savefig('riskdiagram_brc.pdf')\n",
    "    if ret == True:\n",
    "        return r_t_seven,a_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_last14(casos_por_dia):\n",
    "    ac_por_dia = np.copy(casos_por_dia)\n",
    "    for i in casos_por_dia[:,0]:\n",
    "        index = np.copy(casos_por_dia[casos_por_dia[:,0]<i+1])\n",
    "        index = index[i-13<=index[:,0]]\n",
    "        index = index[:,1]\n",
    "        ac_por_dia[i,1] = np.sum(index) \n",
    "    return ac_por_dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cases(fecha_sintomas,pop,a,rep_fun=repratio_t_conv,graph=False,ret=False):\n",
    "    \"\"\"\n",
    "    args: \n",
    "    -fecha_sintomas: day of beginning of symptomps for each case, can't be NaN or NaT (already processed)\n",
    "    -pop: number of inhabitants of the region/population of interest\n",
    "    -rep_fun: function to calculate empirical reproductive ratio. defaults tp repratio_t_conv (not optimized)\n",
    "    -graph: defaults to False. if True, makes graph of risk diagram\n",
    "    -ret: defaults to False. if True, returns the predictions and cases per day\n",
    "    predicts cases per day after calculating the risk diagram, using the empirical reproductive\n",
    "    ratio given by rep_fun\n",
    "    \"\"\"\n",
    "    prox_dia = max(fecha_sintomas)+1\n",
    "    casos_por_dia = new_cases_per_day(fecha_sintomas,ret=True)\n",
    "    r_def,a_t = risk_diagram(fecha_sintomas,pop,a,rep_fun,ret=True)\n",
    "    r_def = r_def[13:]\n",
    "    a_t = a_t[13:]\n",
    "    p_t = r_def * a_t\n",
    "    valid_days = np.arange(19,prox_dia+6,1)\n",
    "    casos_por_dia = sum_last14(casos_por_dia) #gets all active cases in the last 14-days \n",
    "    if graph == True:\n",
    "        plt.style.use('ggplot')\n",
    "        plt.xlabel('Dias desde el comienzo')\n",
    "        plt.ylabel('Infectados activos en BRC')\n",
    "        plt.plot(casos_por_dia[:,0],casos_por_dia[:,1]*(100000/pop),'-ob',markersize=4,label=\"casos hasta dia: \"+str(prox_dia))\n",
    "        plt.plot(valid_days,p_t,linewidth=3,label='prediccion')\n",
    "        plt.legend()\n",
    "        #plt.savefig('9oct_predic_casos.pdf')\n",
    "    if ret == True:\n",
    "        error_global = np.linalg.norm(casos_por_dia[19:,1]-p_t[:-6])\n",
    "        return error_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_dates(df):\n",
    "    #changes fecha_inicio_sintomas according to new criteria\n",
    "    filt_df1 = (df.fecha_inicio_sintomas.isnull()) #filter fecha_inicio_sintomas = inexistant\n",
    "    df_sin_fecha = df.loc[filt_df1]\n",
    "    n_size = df_sin_fecha.shape[0]\n",
    "    df.loc[filt_df1,\"fecha_inicio_sintomas\"] = df.loc[filt_df1,\"fecha_apertura\"] - np.random.randint(0,9,n_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"casos_Bariloche.txt\",sep=\",\",quotechar='\"',\n",
    "                   parse_dates=[\"fecha_inicio_sintomas\",\"fecha_apertura\"],na_values=['']) #data loading\n",
    "df = pd.DataFrame(data) #converting to dataframe for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primer sintoma de persona confirmada:  2020-03-09 00:00:00\n",
      "ultimo sintoma de persona confirmada:  2020-10-24 00:00:00\n",
      "ultima apertura de persona confirmada:  2020-10-25 00:00:00\n"
     ]
    }
   ],
   "source": [
    "inicio_epidemia = min(df[\"fecha_inicio_sintomas\"]) #first symptoms of a person registered\n",
    "ultima_actualizacion_sintomas = max(df[\"fecha_inicio_sintomas\"]) #last day symptoms of a person registered\n",
    "ultima_actualizacion_apertura = max(df[\"fecha_apertura\"])\n",
    "df[\"fecha_inicio_sintomas\"] -= inicio_epidemia #correcting by inicio_epidemia \n",
    "df[\"fecha_apertura\"] -= inicio_epidemia #correcting by inicio_epidemia\n",
    "df.fecha_inicio_sintomas = df.fecha_inicio_sintomas.dt.days #change to int, ditch days \n",
    "df.fecha_apertura = df.fecha_apertura.dt.days #change to int, ditch days\n",
    "change_dates(df) #replaces non existing fecha_inicio_sintomas acc to new criteria\n",
    "print(\"primer sintoma de persona confirmada: \",inicio_epidemia)\n",
    "print(\"ultimo sintoma de persona confirmada: \",ultima_actualizacion_sintomas)\n",
    "print(\"ultima apertura de persona confirmada: \",ultima_actualizacion_apertura)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha_sintomas = df.fecha_inicio_sintomas.to_numpy() #numpy array of fecha_inicio_sintomas\n",
    "fecha_apertura = df.fecha_apertura.to_numpy() #numpy array of fecha_apertura\n",
    "fecha_sintomas = fecha_sintomas.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros(6) + 1\n",
    "pop = 100000\n",
    "rep_fun = repratio_t_conv\n",
    "r_def,a_t = risk_diagram(fecha_sintomas,pop,a,rep_fun,ret=True)\n",
    "a_t = a_t[13:]\n",
    "a_t[a_t.shape[0]-7:] = 0\n",
    "a = np.zeros(a_t.shape[0]+10)\n",
    "a[:a_t.shape[0]] = a_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "casos_por_dia = new_cases_per_day(fecha_sintomas,ret=True)\n",
    "casos_por_dia = sum_last14(casos_por_dia)\n",
    "casos_por_dia = casos_por_dia[20:,1]\n",
    "b = np.zeros(a_t.shape[0]+10)\n",
    "b[:casos_por_dia.shape[0]] = casos_por_dia\n",
    "b = b.reshape(b.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "casos_por_dia = new_cases_per_day(fecha_sintomas,ret=True)\n",
    "n_t = np.copy(casos_por_dia)\n",
    "prox_dia = max(fecha_sintomas) + 1\n",
    "#completing the values for the rest of the values of n_t\n",
    "aux = np.zeros(2)\n",
    "i = 0\n",
    "while i < 4: #completing until the day t+4 bc im gonna need it later for averaging in 7 days\n",
    "    aux[0] = prox_dia + i\n",
    "    aux[1] = np.mean(n_t[prox_dia-7:,1])\n",
    "    n_t  = np.vstack((n_t,aux)) #extending n_t up to day t+1\n",
    "    i= i +1\n",
    "dias = np.copy(n_t[:,0]).astype(int)\n",
    "dias = dias[:-1]\n",
    "m1 = np.zeros((dias[dias>=6].shape[0],3)) #denominator of r7 expression\n",
    "m2 = np.zeros((dias[dias>=6].shape[0],3)) #numerator of r7 expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dias[dias>=6]:\n",
    "    m1[i-6,:] = n_t[i-6:i-3,1]\n",
    "    m2[i-6,:] = n_t[i-1:i+2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dias = m1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_matrix(shape):\n",
    "    n_dias = shape\n",
    "    m = np.zeros((n_dias,n_dias))\n",
    "    i = 0\n",
    "    while i < n_dias - 7:\n",
    "        m[i,i:i+7] = 1/7\n",
    "        i = i + 1\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = m1[11:,:]\n",
    "m2 = m2[11:,:]\n",
    "n_dias = m1.shape[0]\n",
    "a = a[11:]\n",
    "b = b[11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpyA = my_matrix(n_dias)\n",
    "numpyA = keras.backend.variable(numpyA)\n",
    "mat = numpyA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "216/216 [==============================] - 0s 235us/step - loss: 104.0957 - mean_absolute_error: 104.0957\n",
      "Epoch 2/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 104.4260 - mean_absolute_error: 104.4260\n",
      "Epoch 3/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 93.6391 - mean_absolute_error: 93.6391\n",
      "Epoch 4/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 93.5486 - mean_absolute_error: 93.5486\n",
      "Epoch 5/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 96.4303 - mean_absolute_error: 96.4303\n",
      "Epoch 6/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 96.6992 - mean_absolute_error: 96.6992\n",
      "Epoch 7/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 120.5093 - mean_absolute_error: 120.5093\n",
      "Epoch 8/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 112.2256 - mean_absolute_error: 112.2256\n",
      "Epoch 9/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 106.2073 - mean_absolute_error: 106.2073\n",
      "Epoch 10/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 82.6048 - mean_absolute_error: 82.6048\n",
      "Epoch 11/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 102.9163 - mean_absolute_error: 102.9163\n",
      "Epoch 12/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 111.6409 - mean_absolute_error: 111.6409\n",
      "Epoch 13/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 101.1022 - mean_absolute_error: 101.1022\n",
      "Epoch 14/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 106.0747 - mean_absolute_error: 106.0747\n",
      "Epoch 15/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 100.7881 - mean_absolute_error: 100.7881\n",
      "Epoch 16/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 106.9512 - mean_absolute_error: 106.9512\n",
      "Epoch 17/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 101.4666 - mean_absolute_error: 101.4666\n",
      "Epoch 18/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 97.9444 - mean_absolute_error: 97.9444\n",
      "Epoch 19/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 88.0636 - mean_absolute_error: 88.0636\n",
      "Epoch 20/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 87.7398 - mean_absolute_error: 87.7398\n",
      "Epoch 21/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 103.7387 - mean_absolute_error: 103.7387\n",
      "Epoch 22/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 95.7035 - mean_absolute_error: 95.7035\n",
      "Epoch 23/500\n",
      "216/216 [==============================] - 0s 18us/step - loss: 95.6223 - mean_absolute_error: 95.6223\n",
      "Epoch 24/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 101.4977 - mean_absolute_error: 101.4977\n",
      "Epoch 25/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 99.2904 - mean_absolute_error: 99.2904\n",
      "Epoch 26/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 91.0423 - mean_absolute_error: 91.0423\n",
      "Epoch 27/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 81.2564 - mean_absolute_error: 81.2564\n",
      "Epoch 28/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 88.7026 - mean_absolute_error: 88.7026\n",
      "Epoch 29/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 87.2562 - mean_absolute_error: 87.2562\n",
      "Epoch 30/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 98.5509 - mean_absolute_error: 98.5508\n",
      "Epoch 31/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 100.7853 - mean_absolute_error: 100.7853\n",
      "Epoch 32/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 105.7562 - mean_absolute_error: 105.7562\n",
      "Epoch 33/500\n",
      "216/216 [==============================] - 0s 19us/step - loss: 105.5394 - mean_absolute_error: 105.5394\n",
      "Epoch 34/500\n",
      "216/216 [==============================] - 0s 13us/step - loss: 100.0473 - mean_absolute_error: 100.0473\n",
      "Epoch 35/500\n",
      "216/216 [==============================] - 0s 18us/step - loss: 97.8410 - mean_absolute_error: 97.8410\n",
      "Epoch 36/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 91.2891 - mean_absolute_error: 91.2891\n",
      "Epoch 37/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 98.0988 - mean_absolute_error: 98.0988\n",
      "Epoch 38/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 100.7134 - mean_absolute_error: 100.7134\n",
      "Epoch 39/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 88.6526 - mean_absolute_error: 88.6526\n",
      "Epoch 40/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 89.6085 - mean_absolute_error: 89.6085\n",
      "Epoch 41/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 99.0876 - mean_absolute_error: 99.0876\n",
      "Epoch 42/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 88.2569 - mean_absolute_error: 88.2569\n",
      "Epoch 43/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 92.4297 - mean_absolute_error: 92.4297\n",
      "Epoch 44/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 100.4063 - mean_absolute_error: 100.4063\n",
      "Epoch 45/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 93.0233 - mean_absolute_error: 93.0233\n",
      "Epoch 46/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 101.7278 - mean_absolute_error: 101.7278\n",
      "Epoch 47/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 99.5545 - mean_absolute_error: 99.5545\n",
      "Epoch 48/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 86.4207 - mean_absolute_error: 86.4207\n",
      "Epoch 49/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 86.4110 - mean_absolute_error: 86.4110\n",
      "Epoch 50/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 96.8318 - mean_absolute_error: 96.8318\n",
      "Epoch 51/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 95.3660 - mean_absolute_error: 95.3660\n",
      "Epoch 52/500\n",
      "216/216 [==============================] - 0s 18us/step - loss: 98.1031 - mean_absolute_error: 98.1031\n",
      "Epoch 53/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 100.1559 - mean_absolute_error: 100.1559\n",
      "Epoch 54/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 103.6826 - mean_absolute_error: 103.6826\n",
      "Epoch 55/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 95.2297 - mean_absolute_error: 95.2297\n",
      "Epoch 56/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 103.7567 - mean_absolute_error: 103.7567\n",
      "Epoch 57/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 98.4857 - mean_absolute_error: 98.4857\n",
      "Epoch 58/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 88.6569 - mean_absolute_error: 88.6569\n",
      "Epoch 59/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 95.7148 - mean_absolute_error: 95.7148\n",
      "Epoch 60/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 91.1749 - mean_absolute_error: 91.1749\n",
      "Epoch 61/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 108.6824 - mean_absolute_error: 108.6824\n",
      "Epoch 62/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 91.3730 - mean_absolute_error: 91.3730\n",
      "Epoch 63/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 93.1169 - mean_absolute_error: 93.1169\n",
      "Epoch 64/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 92.2545 - mean_absolute_error: 92.2545\n",
      "Epoch 65/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 86.3187 - mean_absolute_error: 86.3187\n",
      "Epoch 66/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 103.7392 - mean_absolute_error: 103.7392\n",
      "Epoch 67/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 84.9749 - mean_absolute_error: 84.9749\n",
      "Epoch 68/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 100.3743 - mean_absolute_error: 100.3743\n",
      "Epoch 69/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 89.3001 - mean_absolute_error: 89.3001\n",
      "Epoch 70/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 94.2099 - mean_absolute_error: 94.2099\n",
      "Epoch 71/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 84.7108 - mean_absolute_error: 84.7108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 86.7367 - mean_absolute_error: 86.7367\n",
      "Epoch 73/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 91.5479 - mean_absolute_error: 91.5479\n",
      "Epoch 74/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 98.9531 - mean_absolute_error: 98.9531\n",
      "Epoch 75/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 88.4080 - mean_absolute_error: 88.4080\n",
      "Epoch 76/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 95.5098 - mean_absolute_error: 95.5098\n",
      "Epoch 77/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 94.1991 - mean_absolute_error: 94.1991\n",
      "Epoch 78/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 83.9857 - mean_absolute_error: 83.9857\n",
      "Epoch 79/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 88.2428 - mean_absolute_error: 88.2428\n",
      "Epoch 80/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 91.0936 - mean_absolute_error: 91.0936\n",
      "Epoch 81/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 94.1201 - mean_absolute_error: 94.1201\n",
      "Epoch 82/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 104.5161 - mean_absolute_error: 104.5161\n",
      "Epoch 83/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 87.6427 - mean_absolute_error: 87.6427\n",
      "Epoch 84/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 91.2219 - mean_absolute_error: 91.2219\n",
      "Epoch 85/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 85.4237 - mean_absolute_error: 85.4237\n",
      "Epoch 86/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 98.4605 - mean_absolute_error: 98.4605\n",
      "Epoch 87/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 87.8867 - mean_absolute_error: 87.8867\n",
      "Epoch 88/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 87.6685 - mean_absolute_error: 87.6685\n",
      "Epoch 89/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 90.8185 - mean_absolute_error: 90.8185\n",
      "Epoch 90/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 78.3035 - mean_absolute_error: 78.3035\n",
      "Epoch 91/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 90.2533 - mean_absolute_error: 90.2533\n",
      "Epoch 92/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 78.9400 - mean_absolute_error: 78.9400\n",
      "Epoch 93/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 99.6434 - mean_absolute_error: 99.6434\n",
      "Epoch 94/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 101.8242 - mean_absolute_error: 101.8242\n",
      "Epoch 95/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 86.0460 - mean_absolute_error: 86.0460\n",
      "Epoch 96/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 90.6965 - mean_absolute_error: 90.6965\n",
      "Epoch 97/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 85.9013 - mean_absolute_error: 85.9013\n",
      "Epoch 98/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 98.2187 - mean_absolute_error: 98.2187\n",
      "Epoch 99/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 80.2573 - mean_absolute_error: 80.2573\n",
      "Epoch 100/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 84.8545 - mean_absolute_error: 84.8545\n",
      "Epoch 101/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 86.5828 - mean_absolute_error: 86.5828\n",
      "Epoch 102/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 84.8596 - mean_absolute_error: 84.8596\n",
      "Epoch 103/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 93.1907 - mean_absolute_error: 93.1907\n",
      "Epoch 104/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 94.1277 - mean_absolute_error: 94.1277\n",
      "Epoch 105/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 79.0947 - mean_absolute_error: 79.0947\n",
      "Epoch 106/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 93.6050 - mean_absolute_error: 93.6050\n",
      "Epoch 107/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 87.6325 - mean_absolute_error: 87.6325\n",
      "Epoch 108/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 90.7125 - mean_absolute_error: 90.7125\n",
      "Epoch 109/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 84.9986 - mean_absolute_error: 84.9986\n",
      "Epoch 110/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 80.8801 - mean_absolute_error: 80.8801\n",
      "Epoch 111/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 80.2234 - mean_absolute_error: 80.2234\n",
      "Epoch 112/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 93.2399 - mean_absolute_error: 93.2399\n",
      "Epoch 113/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 94.1766 - mean_absolute_error: 94.1766\n",
      "Epoch 114/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 88.9568 - mean_absolute_error: 88.9568\n",
      "Epoch 115/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 93.9507 - mean_absolute_error: 93.9507\n",
      "Epoch 116/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 83.4459 - mean_absolute_error: 83.4459\n",
      "Epoch 117/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 100.3718 - mean_absolute_error: 100.3718\n",
      "Epoch 118/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 94.8549 - mean_absolute_error: 94.8549\n",
      "Epoch 119/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 100.8948 - mean_absolute_error: 100.8947\n",
      "Epoch 120/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 96.8798 - mean_absolute_error: 96.8798\n",
      "Epoch 121/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 91.5770 - mean_absolute_error: 91.5770\n",
      "Epoch 122/500\n",
      "216/216 [==============================] - 0s 18us/step - loss: 87.5414 - mean_absolute_error: 87.5414\n",
      "Epoch 123/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 83.9970 - mean_absolute_error: 83.9970\n",
      "Epoch 124/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 77.7004 - mean_absolute_error: 77.7004\n",
      "Epoch 125/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 93.8349 - mean_absolute_error: 93.8349\n",
      "Epoch 126/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 104.0716 - mean_absolute_error: 104.0716\n",
      "Epoch 127/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 91.1428 - mean_absolute_error: 91.1428\n",
      "Epoch 128/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 82.0250 - mean_absolute_error: 82.0250\n",
      "Epoch 129/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 87.4298 - mean_absolute_error: 87.4298\n",
      "Epoch 130/500\n",
      "216/216 [==============================] - 0s 12us/step - loss: 89.6032 - mean_absolute_error: 89.6032\n",
      "Epoch 131/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 91.5594 - mean_absolute_error: 91.5594\n",
      "Epoch 132/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 83.4303 - mean_absolute_error: 83.4303\n",
      "Epoch 133/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 99.0085 - mean_absolute_error: 99.0085\n",
      "Epoch 134/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 84.0727 - mean_absolute_error: 84.0727\n",
      "Epoch 135/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 87.4475 - mean_absolute_error: 87.4475\n",
      "Epoch 136/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 98.4014 - mean_absolute_error: 98.4014\n",
      "Epoch 137/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 87.7811 - mean_absolute_error: 87.7811\n",
      "Epoch 138/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 87.1150 - mean_absolute_error: 87.1150\n",
      "Epoch 139/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 85.0426 - mean_absolute_error: 85.0426\n",
      "Epoch 140/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 92.8658 - mean_absolute_error: 92.8658\n",
      "Epoch 141/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 95.1153 - mean_absolute_error: 95.1153\n",
      "Epoch 142/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 114.3112 - mean_absolute_error: 114.3112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 91.3050 - mean_absolute_error: 91.3050\n",
      "Epoch 144/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 80.5228 - mean_absolute_error: 80.5228\n",
      "Epoch 145/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 74.5333 - mean_absolute_error: 74.5333\n",
      "Epoch 146/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 97.8647 - mean_absolute_error: 97.8647\n",
      "Epoch 147/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 88.3677 - mean_absolute_error: 88.3677\n",
      "Epoch 148/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 90.8186 - mean_absolute_error: 90.8186\n",
      "Epoch 149/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 90.5951 - mean_absolute_error: 90.5951\n",
      "Epoch 150/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 87.5204 - mean_absolute_error: 87.5204\n",
      "Epoch 151/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 86.0652 - mean_absolute_error: 86.0652\n",
      "Epoch 152/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 85.6486 - mean_absolute_error: 85.6486\n",
      "Epoch 153/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 106.4847 - mean_absolute_error: 106.4847\n",
      "Epoch 154/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 91.4768 - mean_absolute_error: 91.4768\n",
      "Epoch 155/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 86.2417 - mean_absolute_error: 86.2417\n",
      "Epoch 156/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 93.4627 - mean_absolute_error: 93.4627\n",
      "Epoch 157/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 95.2208 - mean_absolute_error: 95.2208\n",
      "Epoch 158/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 92.0738 - mean_absolute_error: 92.0738\n",
      "Epoch 159/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 88.6400 - mean_absolute_error: 88.6400\n",
      "Epoch 160/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 89.7489 - mean_absolute_error: 89.7489\n",
      "Epoch 161/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 91.6750 - mean_absolute_error: 91.6750\n",
      "Epoch 162/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 85.4635 - mean_absolute_error: 85.4635\n",
      "Epoch 163/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 87.6198 - mean_absolute_error: 87.6198\n",
      "Epoch 164/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 98.1894 - mean_absolute_error: 98.1894\n",
      "Epoch 165/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 91.0694 - mean_absolute_error: 91.0694\n",
      "Epoch 166/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 93.7390 - mean_absolute_error: 93.7390\n",
      "Epoch 167/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 79.6762 - mean_absolute_error: 79.6762\n",
      "Epoch 168/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 91.1397 - mean_absolute_error: 91.1397\n",
      "Epoch 169/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 88.4328 - mean_absolute_error: 88.4328\n",
      "Epoch 170/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 94.2189 - mean_absolute_error: 94.2189\n",
      "Epoch 171/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 88.2093 - mean_absolute_error: 88.2093\n",
      "Epoch 172/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 87.1050 - mean_absolute_error: 87.1050\n",
      "Epoch 173/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 98.0078 - mean_absolute_error: 98.0078\n",
      "Epoch 174/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 93.7377 - mean_absolute_error: 93.7377\n",
      "Epoch 175/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 86.5721 - mean_absolute_error: 86.5721\n",
      "Epoch 176/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 82.9209 - mean_absolute_error: 82.9209\n",
      "Epoch 177/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 100.7447 - mean_absolute_error: 100.7447\n",
      "Epoch 178/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 97.3312 - mean_absolute_error: 97.3312\n",
      "Epoch 179/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 95.9894 - mean_absolute_error: 95.9894\n",
      "Epoch 180/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 81.0868 - mean_absolute_error: 81.0868\n",
      "Epoch 181/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 83.5483 - mean_absolute_error: 83.5483\n",
      "Epoch 182/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 88.7382 - mean_absolute_error: 88.7382\n",
      "Epoch 183/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 83.4132 - mean_absolute_error: 83.4132\n",
      "Epoch 184/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 92.3508 - mean_absolute_error: 92.3508\n",
      "Epoch 185/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 82.6273 - mean_absolute_error: 82.6273\n",
      "Epoch 186/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 91.4952 - mean_absolute_error: 91.4952\n",
      "Epoch 187/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 86.3993 - mean_absolute_error: 86.3993\n",
      "Epoch 188/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 88.0927 - mean_absolute_error: 88.0927\n",
      "Epoch 189/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 83.9293 - mean_absolute_error: 83.9293\n",
      "Epoch 190/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 98.9535 - mean_absolute_error: 98.9535\n",
      "Epoch 191/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 81.2727 - mean_absolute_error: 81.2727\n",
      "Epoch 192/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 93.4295 - mean_absolute_error: 93.4295\n",
      "Epoch 193/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 93.9688 - mean_absolute_error: 93.9688\n",
      "Epoch 194/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 91.5774 - mean_absolute_error: 91.5774\n",
      "Epoch 195/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 83.7969 - mean_absolute_error: 83.7969\n",
      "Epoch 196/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 95.7248 - mean_absolute_error: 95.7248\n",
      "Epoch 197/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 95.7262 - mean_absolute_error: 95.7262\n",
      "Epoch 198/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 85.2204 - mean_absolute_error: 85.2204\n",
      "Epoch 199/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 87.4734 - mean_absolute_error: 87.4734\n",
      "Epoch 200/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 88.5057 - mean_absolute_error: 88.5057\n",
      "Epoch 201/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 88.4779 - mean_absolute_error: 88.4779\n",
      "Epoch 202/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 97.5260 - mean_absolute_error: 97.5260\n",
      "Epoch 203/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 96.0054 - mean_absolute_error: 96.0054\n",
      "Epoch 204/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 89.7962 - mean_absolute_error: 89.7962\n",
      "Epoch 205/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 89.2531 - mean_absolute_error: 89.2531\n",
      "Epoch 206/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 94.7203 - mean_absolute_error: 94.7203\n",
      "Epoch 207/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 82.8459 - mean_absolute_error: 82.8459\n",
      "Epoch 208/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 88.7797 - mean_absolute_error: 88.7797\n",
      "Epoch 209/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 86.5758 - mean_absolute_error: 86.5758\n",
      "Epoch 210/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 93.3707 - mean_absolute_error: 93.3707\n",
      "Epoch 211/500\n",
      "216/216 [==============================] - 0s 18us/step - loss: 97.0900 - mean_absolute_error: 97.0900\n",
      "Epoch 212/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 95.1028 - mean_absolute_error: 95.1028\n",
      "Epoch 213/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 88.1579 - mean_absolute_error: 88.1579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 214/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 87.2545 - mean_absolute_error: 87.2545\n",
      "Epoch 215/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 90.8098 - mean_absolute_error: 90.8098\n",
      "Epoch 216/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 95.8905 - mean_absolute_error: 95.8905\n",
      "Epoch 217/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 81.4234 - mean_absolute_error: 81.4234\n",
      "Epoch 218/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 91.4329 - mean_absolute_error: 91.4329\n",
      "Epoch 219/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 89.9718 - mean_absolute_error: 89.9718\n",
      "Epoch 220/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 84.3843 - mean_absolute_error: 84.3843\n",
      "Epoch 221/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 91.6999 - mean_absolute_error: 91.6999\n",
      "Epoch 222/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 91.0350 - mean_absolute_error: 91.0350\n",
      "Epoch 223/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 81.0571 - mean_absolute_error: 81.0571\n",
      "Epoch 224/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 86.7667 - mean_absolute_error: 86.7667\n",
      "Epoch 225/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 84.9707 - mean_absolute_error: 84.9707\n",
      "Epoch 226/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 86.2467 - mean_absolute_error: 86.2467\n",
      "Epoch 227/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 88.8796 - mean_absolute_error: 88.8796\n",
      "Epoch 228/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 92.4747 - mean_absolute_error: 92.4747\n",
      "Epoch 229/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 81.5434 - mean_absolute_error: 81.5434\n",
      "Epoch 230/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 88.1691 - mean_absolute_error: 88.1691\n",
      "Epoch 231/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 87.9877 - mean_absolute_error: 87.9877\n",
      "Epoch 232/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 85.8311 - mean_absolute_error: 85.8311\n",
      "Epoch 233/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 95.5561 - mean_absolute_error: 95.5561\n",
      "Epoch 234/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 89.4199 - mean_absolute_error: 89.4199\n",
      "Epoch 235/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 91.4126 - mean_absolute_error: 91.4126\n",
      "Epoch 236/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 92.3304 - mean_absolute_error: 92.3304\n",
      "Epoch 237/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 100.7406 - mean_absolute_error: 100.7406\n",
      "Epoch 238/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 87.3402 - mean_absolute_error: 87.3402\n",
      "Epoch 239/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 108.3724 - mean_absolute_error: 108.3724\n",
      "Epoch 240/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 81.9354 - mean_absolute_error: 81.9354\n",
      "Epoch 241/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 83.7797 - mean_absolute_error: 83.7797\n",
      "Epoch 242/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 76.7488 - mean_absolute_error: 76.7488\n",
      "Epoch 243/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 94.8043 - mean_absolute_error: 94.8043\n",
      "Epoch 244/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 87.7224 - mean_absolute_error: 87.7224\n",
      "Epoch 245/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 90.8677 - mean_absolute_error: 90.8677\n",
      "Epoch 246/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 98.0169 - mean_absolute_error: 98.0169\n",
      "Epoch 247/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 88.8818 - mean_absolute_error: 88.8818\n",
      "Epoch 248/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 93.5194 - mean_absolute_error: 93.5194\n",
      "Epoch 249/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 92.2472 - mean_absolute_error: 92.2472\n",
      "Epoch 250/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 94.1964 - mean_absolute_error: 94.1964\n",
      "Epoch 251/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 94.8250 - mean_absolute_error: 94.8250\n",
      "Epoch 252/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 83.3096 - mean_absolute_error: 83.3096\n",
      "Epoch 253/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 99.7596 - mean_absolute_error: 99.7596\n",
      "Epoch 254/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 88.6282 - mean_absolute_error: 88.6282\n",
      "Epoch 255/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 96.2525 - mean_absolute_error: 96.2525\n",
      "Epoch 256/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 88.6341 - mean_absolute_error: 88.6341\n",
      "Epoch 257/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 93.9592 - mean_absolute_error: 93.9592\n",
      "Epoch 258/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 82.6087 - mean_absolute_error: 82.6087\n",
      "Epoch 259/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 94.5401 - mean_absolute_error: 94.5401\n",
      "Epoch 260/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 78.2232 - mean_absolute_error: 78.2232\n",
      "Epoch 261/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 79.4976 - mean_absolute_error: 79.4976\n",
      "Epoch 262/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 90.7424 - mean_absolute_error: 90.7424\n",
      "Epoch 263/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 99.6548 - mean_absolute_error: 99.6548\n",
      "Epoch 264/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 96.1170 - mean_absolute_error: 96.1170\n",
      "Epoch 265/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 91.5034 - mean_absolute_error: 91.5034\n",
      "Epoch 266/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 93.7988 - mean_absolute_error: 93.7988\n",
      "Epoch 267/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 83.2426 - mean_absolute_error: 83.2426\n",
      "Epoch 268/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 88.2666 - mean_absolute_error: 88.2666\n",
      "Epoch 269/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 85.0662 - mean_absolute_error: 85.0662\n",
      "Epoch 270/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 88.3216 - mean_absolute_error: 88.3216\n",
      "Epoch 271/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 84.3849 - mean_absolute_error: 84.3849\n",
      "Epoch 272/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 90.2506 - mean_absolute_error: 90.2506\n",
      "Epoch 273/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 89.6129 - mean_absolute_error: 89.6129\n",
      "Epoch 274/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 94.8185 - mean_absolute_error: 94.8185\n",
      "Epoch 275/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 98.2075 - mean_absolute_error: 98.2075\n",
      "Epoch 276/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 95.5637 - mean_absolute_error: 95.5637\n",
      "Epoch 277/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 96.3418 - mean_absolute_error: 96.3418\n",
      "Epoch 278/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 77.7257 - mean_absolute_error: 77.7257\n",
      "Epoch 279/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 91.6228 - mean_absolute_error: 91.6228\n",
      "Epoch 280/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 92.9847 - mean_absolute_error: 92.9847\n",
      "Epoch 281/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 83.8732 - mean_absolute_error: 83.8732\n",
      "Epoch 282/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 82.7178 - mean_absolute_error: 82.7178\n",
      "Epoch 283/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 79.1880 - mean_absolute_error: 79.1880\n",
      "Epoch 284/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 84.4423 - mean_absolute_error: 84.4423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 285/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 76.8930 - mean_absolute_error: 76.8930\n",
      "Epoch 286/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 91.1463 - mean_absolute_error: 91.1463\n",
      "Epoch 287/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 84.7595 - mean_absolute_error: 84.7595\n",
      "Epoch 288/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 101.6427 - mean_absolute_error: 101.6427\n",
      "Epoch 289/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 88.5118 - mean_absolute_error: 88.5118\n",
      "Epoch 290/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 87.4715 - mean_absolute_error: 87.4715\n",
      "Epoch 291/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 83.6722 - mean_absolute_error: 83.6722\n",
      "Epoch 292/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 97.2360 - mean_absolute_error: 97.2360\n",
      "Epoch 293/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 75.6400 - mean_absolute_error: 75.6400\n",
      "Epoch 294/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 86.1724 - mean_absolute_error: 86.1724\n",
      "Epoch 295/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 78.9067 - mean_absolute_error: 78.9067\n",
      "Epoch 296/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 87.3491 - mean_absolute_error: 87.3491\n",
      "Epoch 297/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 93.5644 - mean_absolute_error: 93.5644\n",
      "Epoch 298/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 109.8017 - mean_absolute_error: 109.8017\n",
      "Epoch 299/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 93.0974 - mean_absolute_error: 93.0974\n",
      "Epoch 300/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 78.3742 - mean_absolute_error: 78.3742\n",
      "Epoch 301/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 88.9916 - mean_absolute_error: 88.9916\n",
      "Epoch 302/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 94.6969 - mean_absolute_error: 94.6968\n",
      "Epoch 303/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 93.1299 - mean_absolute_error: 93.1299\n",
      "Epoch 304/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 84.9831 - mean_absolute_error: 84.9831\n",
      "Epoch 305/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 87.9689 - mean_absolute_error: 87.9689\n",
      "Epoch 306/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 85.1938 - mean_absolute_error: 85.1938\n",
      "Epoch 307/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 99.6672 - mean_absolute_error: 99.6672\n",
      "Epoch 308/500\n",
      "216/216 [==============================] - 0s 18us/step - loss: 82.8939 - mean_absolute_error: 82.8939\n",
      "Epoch 309/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 89.7781 - mean_absolute_error: 89.7780\n",
      "Epoch 310/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 94.7312 - mean_absolute_error: 94.7312\n",
      "Epoch 311/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 83.7724 - mean_absolute_error: 83.7724\n",
      "Epoch 312/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 84.7792 - mean_absolute_error: 84.7792\n",
      "Epoch 313/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 85.0713 - mean_absolute_error: 85.0713\n",
      "Epoch 314/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 85.7086 - mean_absolute_error: 85.7086\n",
      "Epoch 315/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 90.4527 - mean_absolute_error: 90.4527\n",
      "Epoch 316/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 84.4335 - mean_absolute_error: 84.4335\n",
      "Epoch 317/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 87.9973 - mean_absolute_error: 87.9973\n",
      "Epoch 318/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 91.5832 - mean_absolute_error: 91.5832\n",
      "Epoch 319/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 95.0901 - mean_absolute_error: 95.0901\n",
      "Epoch 320/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 90.1119 - mean_absolute_error: 90.1119\n",
      "Epoch 321/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 96.1099 - mean_absolute_error: 96.1099\n",
      "Epoch 322/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 95.8329 - mean_absolute_error: 95.8329\n",
      "Epoch 323/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 80.9699 - mean_absolute_error: 80.9699\n",
      "Epoch 324/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 81.2548 - mean_absolute_error: 81.2548\n",
      "Epoch 325/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 88.5299 - mean_absolute_error: 88.5299\n",
      "Epoch 326/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 98.9334 - mean_absolute_error: 98.9334\n",
      "Epoch 327/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 92.4824 - mean_absolute_error: 92.4824\n",
      "Epoch 328/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 86.1085 - mean_absolute_error: 86.1085\n",
      "Epoch 329/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 87.8104 - mean_absolute_error: 87.8104\n",
      "Epoch 330/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 96.4960 - mean_absolute_error: 96.4960\n",
      "Epoch 331/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 84.8940 - mean_absolute_error: 84.8940\n",
      "Epoch 332/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 81.4437 - mean_absolute_error: 81.4437\n",
      "Epoch 333/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 106.1914 - mean_absolute_error: 106.1914\n",
      "Epoch 334/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 90.6075 - mean_absolute_error: 90.6075\n",
      "Epoch 335/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 92.5475 - mean_absolute_error: 92.5475\n",
      "Epoch 336/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 90.0971 - mean_absolute_error: 90.0971\n",
      "Epoch 337/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 91.5374 - mean_absolute_error: 91.5374\n",
      "Epoch 338/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 82.4128 - mean_absolute_error: 82.4128\n",
      "Epoch 339/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 90.9537 - mean_absolute_error: 90.9537\n",
      "Epoch 340/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 86.0205 - mean_absolute_error: 86.0205\n",
      "Epoch 341/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 85.4823 - mean_absolute_error: 85.4823\n",
      "Epoch 342/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 95.5454 - mean_absolute_error: 95.5454\n",
      "Epoch 343/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 90.6364 - mean_absolute_error: 90.6364\n",
      "Epoch 344/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 92.4112 - mean_absolute_error: 92.4112\n",
      "Epoch 345/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 91.0739 - mean_absolute_error: 91.0739\n",
      "Epoch 346/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 93.8023 - mean_absolute_error: 93.8023\n",
      "Epoch 347/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 81.8386 - mean_absolute_error: 81.8386\n",
      "Epoch 348/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 93.1638 - mean_absolute_error: 93.1638\n",
      "Epoch 349/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 80.5094 - mean_absolute_error: 80.5094\n",
      "Epoch 350/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 75.1979 - mean_absolute_error: 75.1979\n",
      "Epoch 351/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 91.3108 - mean_absolute_error: 91.3108\n",
      "Epoch 352/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 80.3400 - mean_absolute_error: 80.3400\n",
      "Epoch 353/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 87.6950 - mean_absolute_error: 87.6950\n",
      "Epoch 354/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 82.3413 - mean_absolute_error: 82.3413\n",
      "Epoch 355/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 90.4903 - mean_absolute_error: 90.4903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 356/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 92.2115 - mean_absolute_error: 92.2115\n",
      "Epoch 357/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 81.9943 - mean_absolute_error: 81.9943\n",
      "Epoch 358/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 95.4544 - mean_absolute_error: 95.4544\n",
      "Epoch 359/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 86.7340 - mean_absolute_error: 86.7340\n",
      "Epoch 360/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 88.5350 - mean_absolute_error: 88.5350\n",
      "Epoch 361/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 84.4840 - mean_absolute_error: 84.4840\n",
      "Epoch 362/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 81.6530 - mean_absolute_error: 81.6530\n",
      "Epoch 363/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 90.6327 - mean_absolute_error: 90.6327\n",
      "Epoch 364/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 91.0980 - mean_absolute_error: 91.0980\n",
      "Epoch 365/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 95.7568 - mean_absolute_error: 95.7568\n",
      "Epoch 366/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 82.4140 - mean_absolute_error: 82.4140\n",
      "Epoch 367/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 94.2084 - mean_absolute_error: 94.2084\n",
      "Epoch 368/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 80.8536 - mean_absolute_error: 80.8536\n",
      "Epoch 369/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 88.0315 - mean_absolute_error: 88.0315\n",
      "Epoch 370/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 87.1187 - mean_absolute_error: 87.1187\n",
      "Epoch 371/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 98.3094 - mean_absolute_error: 98.3094\n",
      "Epoch 372/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 89.9319 - mean_absolute_error: 89.9319\n",
      "Epoch 373/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 80.0285 - mean_absolute_error: 80.0285\n",
      "Epoch 374/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 86.1375 - mean_absolute_error: 86.1375\n",
      "Epoch 375/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 94.7433 - mean_absolute_error: 94.7433\n",
      "Epoch 376/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 89.8376 - mean_absolute_error: 89.8376\n",
      "Epoch 377/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 86.7438 - mean_absolute_error: 86.7438\n",
      "Epoch 378/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 92.2135 - mean_absolute_error: 92.2135\n",
      "Epoch 379/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 81.9292 - mean_absolute_error: 81.9292\n",
      "Epoch 380/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 86.4057 - mean_absolute_error: 86.4057\n",
      "Epoch 381/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 97.9943 - mean_absolute_error: 97.9943\n",
      "Epoch 382/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 88.2987 - mean_absolute_error: 88.2987\n",
      "Epoch 383/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 95.2578 - mean_absolute_error: 95.2578\n",
      "Epoch 384/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 84.7293 - mean_absolute_error: 84.7293\n",
      "Epoch 385/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 92.2228 - mean_absolute_error: 92.2228\n",
      "Epoch 386/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 81.5583 - mean_absolute_error: 81.5583\n",
      "Epoch 387/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 86.0215 - mean_absolute_error: 86.0215\n",
      "Epoch 388/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 97.5192 - mean_absolute_error: 97.5192\n",
      "Epoch 389/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 86.1816 - mean_absolute_error: 86.1816\n",
      "Epoch 390/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 95.0693 - mean_absolute_error: 95.0693\n",
      "Epoch 391/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 93.3135 - mean_absolute_error: 93.3134\n",
      "Epoch 392/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 98.7555 - mean_absolute_error: 98.7555\n",
      "Epoch 393/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 93.1760 - mean_absolute_error: 93.1760\n",
      "Epoch 394/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 90.1378 - mean_absolute_error: 90.1378\n",
      "Epoch 395/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 83.0048 - mean_absolute_error: 83.0048\n",
      "Epoch 396/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 79.1703 - mean_absolute_error: 79.1703\n",
      "Epoch 397/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 90.9290 - mean_absolute_error: 90.9290\n",
      "Epoch 398/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 81.1400 - mean_absolute_error: 81.1400\n",
      "Epoch 399/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 94.5948 - mean_absolute_error: 94.5948\n",
      "Epoch 400/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 88.1833 - mean_absolute_error: 88.1833\n",
      "Epoch 401/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 98.4698 - mean_absolute_error: 98.4698\n",
      "Epoch 402/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 89.7998 - mean_absolute_error: 89.7998\n",
      "Epoch 403/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 86.6526 - mean_absolute_error: 86.6526\n",
      "Epoch 404/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 90.9174 - mean_absolute_error: 90.9174\n",
      "Epoch 405/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 100.3202 - mean_absolute_error: 100.3202\n",
      "Epoch 406/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 81.0659 - mean_absolute_error: 81.0659\n",
      "Epoch 407/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 90.5547 - mean_absolute_error: 90.5547\n",
      "Epoch 408/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 79.2875 - mean_absolute_error: 79.2875\n",
      "Epoch 409/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 84.4786 - mean_absolute_error: 84.4786\n",
      "Epoch 410/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 89.1376 - mean_absolute_error: 89.1376\n",
      "Epoch 411/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 98.1838 - mean_absolute_error: 98.1838\n",
      "Epoch 412/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 93.0378 - mean_absolute_error: 93.0378\n",
      "Epoch 413/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 86.0540 - mean_absolute_error: 86.0540\n",
      "Epoch 414/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 83.9846 - mean_absolute_error: 83.9846\n",
      "Epoch 415/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 89.5494 - mean_absolute_error: 89.5494\n",
      "Epoch 416/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 95.0243 - mean_absolute_error: 95.0243\n",
      "Epoch 417/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 95.2543 - mean_absolute_error: 95.2543\n",
      "Epoch 418/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 84.4270 - mean_absolute_error: 84.4270\n",
      "Epoch 419/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 88.8432 - mean_absolute_error: 88.8432\n",
      "Epoch 420/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 95.8616 - mean_absolute_error: 95.8616\n",
      "Epoch 421/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 88.9997 - mean_absolute_error: 88.9997\n",
      "Epoch 422/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 85.4135 - mean_absolute_error: 85.4135\n",
      "Epoch 423/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 87.9022 - mean_absolute_error: 87.9022\n",
      "Epoch 424/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 90.6602 - mean_absolute_error: 90.6602\n",
      "Epoch 425/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 86.2555 - mean_absolute_error: 86.2555\n",
      "Epoch 426/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 94.0217 - mean_absolute_error: 94.0217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 427/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 81.0950 - mean_absolute_error: 81.0950\n",
      "Epoch 428/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 85.2499 - mean_absolute_error: 85.2499\n",
      "Epoch 429/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 79.2986 - mean_absolute_error: 79.2986\n",
      "Epoch 430/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 92.3601 - mean_absolute_error: 92.3601\n",
      "Epoch 431/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 89.9478 - mean_absolute_error: 89.9478\n",
      "Epoch 432/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 83.9387 - mean_absolute_error: 83.9387\n",
      "Epoch 433/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 90.0050 - mean_absolute_error: 90.0050\n",
      "Epoch 434/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 78.8778 - mean_absolute_error: 78.8778\n",
      "Epoch 435/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 97.1003 - mean_absolute_error: 97.1003\n",
      "Epoch 436/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 98.5068 - mean_absolute_error: 98.5068\n",
      "Epoch 437/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 84.3394 - mean_absolute_error: 84.3394\n",
      "Epoch 438/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 88.6043 - mean_absolute_error: 88.6043\n",
      "Epoch 439/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 92.1361 - mean_absolute_error: 92.1361\n",
      "Epoch 440/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 86.3086 - mean_absolute_error: 86.3086\n",
      "Epoch 441/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 95.7013 - mean_absolute_error: 95.7013\n",
      "Epoch 442/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 82.2624 - mean_absolute_error: 82.2624\n",
      "Epoch 443/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 95.7074 - mean_absolute_error: 95.7074\n",
      "Epoch 444/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 83.3386 - mean_absolute_error: 83.3386\n",
      "Epoch 445/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 90.2170 - mean_absolute_error: 90.2170\n",
      "Epoch 446/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 83.6644 - mean_absolute_error: 83.6644\n",
      "Epoch 447/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 85.1939 - mean_absolute_error: 85.1939\n",
      "Epoch 448/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 82.7295 - mean_absolute_error: 82.7295\n",
      "Epoch 449/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 80.9405 - mean_absolute_error: 80.9405\n",
      "Epoch 450/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 92.5948 - mean_absolute_error: 92.5948\n",
      "Epoch 451/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 93.2258 - mean_absolute_error: 93.2258\n",
      "Epoch 452/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 81.6550 - mean_absolute_error: 81.6550\n",
      "Epoch 453/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 91.2598 - mean_absolute_error: 91.2598\n",
      "Epoch 454/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 92.7423 - mean_absolute_error: 92.7423\n",
      "Epoch 455/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 80.4387 - mean_absolute_error: 80.4387\n",
      "Epoch 456/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 83.9365 - mean_absolute_error: 83.9365\n",
      "Epoch 457/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 91.3578 - mean_absolute_error: 91.3578\n",
      "Epoch 458/500\n",
      "216/216 [==============================] - 0s 18us/step - loss: 92.2824 - mean_absolute_error: 92.2824\n",
      "Epoch 459/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 86.7441 - mean_absolute_error: 86.7441\n",
      "Epoch 460/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 87.7389 - mean_absolute_error: 87.7389\n",
      "Epoch 461/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 95.8099 - mean_absolute_error: 95.8099\n",
      "Epoch 462/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 96.7248 - mean_absolute_error: 96.7248\n",
      "Epoch 463/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 81.3586 - mean_absolute_error: 81.3586\n",
      "Epoch 464/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 82.0456 - mean_absolute_error: 82.0456\n",
      "Epoch 465/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 90.8634 - mean_absolute_error: 90.8634\n",
      "Epoch 466/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 87.8455 - mean_absolute_error: 87.8455\n",
      "Epoch 467/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 85.1486 - mean_absolute_error: 85.1486\n",
      "Epoch 468/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 83.6954 - mean_absolute_error: 83.6954\n",
      "Epoch 469/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 87.5323 - mean_absolute_error: 87.5323\n",
      "Epoch 470/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 89.3905 - mean_absolute_error: 89.3904\n",
      "Epoch 471/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 85.1293 - mean_absolute_error: 85.1293\n",
      "Epoch 472/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 85.8228 - mean_absolute_error: 85.8228\n",
      "Epoch 473/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 78.9222 - mean_absolute_error: 78.9222\n",
      "Epoch 474/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 78.9004 - mean_absolute_error: 78.9004\n",
      "Epoch 475/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 85.9703 - mean_absolute_error: 85.9703\n",
      "Epoch 476/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 86.1374 - mean_absolute_error: 86.1374\n",
      "Epoch 477/500\n",
      "216/216 [==============================] - 0s 18us/step - loss: 97.1716 - mean_absolute_error: 97.1716\n",
      "Epoch 478/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 78.9990 - mean_absolute_error: 78.9990\n",
      "Epoch 479/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 100.1484 - mean_absolute_error: 100.1484\n",
      "Epoch 480/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 89.6428 - mean_absolute_error: 89.6428\n",
      "Epoch 481/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 93.4511 - mean_absolute_error: 93.4511\n",
      "Epoch 482/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 97.2154 - mean_absolute_error: 97.2154\n",
      "Epoch 483/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 85.3632 - mean_absolute_error: 85.3632\n",
      "Epoch 484/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 89.9008 - mean_absolute_error: 89.9008\n",
      "Epoch 485/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 86.9323 - mean_absolute_error: 86.9323\n",
      "Epoch 486/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 85.6655 - mean_absolute_error: 85.6655\n",
      "Epoch 487/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 89.1052 - mean_absolute_error: 89.1052\n",
      "Epoch 488/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 82.5891 - mean_absolute_error: 82.5891\n",
      "Epoch 489/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 94.6365 - mean_absolute_error: 94.6365\n",
      "Epoch 490/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 85.1596 - mean_absolute_error: 85.1596\n",
      "Epoch 491/500\n",
      "216/216 [==============================] - 0s 12us/step - loss: 84.1061 - mean_absolute_error: 84.1061\n",
      "Epoch 492/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 81.6445 - mean_absolute_error: 81.6445\n",
      "Epoch 493/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 95.9048 - mean_absolute_error: 95.9048\n",
      "Epoch 494/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 91.8616 - mean_absolute_error: 91.8616\n",
      "Epoch 495/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 81.9467 - mean_absolute_error: 81.9467\n",
      "Epoch 496/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 75.8119 - mean_absolute_error: 75.8119\n",
      "Epoch 497/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 88.9849 - mean_absolute_error: 88.9849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 498/500\n",
      "216/216 [==============================] - 0s 9us/step - loss: 91.0977 - mean_absolute_error: 91.0977\n",
      "Epoch 499/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 88.9207 - mean_absolute_error: 88.9207\n",
      "Epoch 500/500\n",
      "216/216 [==============================] - 0s 14us/step - loss: 85.9811 - mean_absolute_error: 85.9811\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_16 (InputLayer)           (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_17 (InputLayer)           (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1)            3           input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1)            3           input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1)            0           dense_11[0][0]                   \n",
      "                                                                 dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (216, 1)             0           lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (216, 1)             0           input_18[0][0]                   \n",
      "                                                                 lambda_12[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6\n",
      "Trainable params: 6\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_1 = keras.layers.Input(shape=(3,))\n",
    "input_2 = keras.layers.Input(shape=(3,))\n",
    "input_3 = keras.layers.Input(shape=(1,))\n",
    "initializer = keras.initializers.Ones() #the vector of weights a\n",
    "l_input_1 = keras.layers.Dense(1,activation='linear',use_bias=False,kernel_initializer=initializer,kernel_regularizer=keras.regularizers.l2(1e-6))(input_1)\n",
    "l_input_2 = keras.layers.Dense(1,activation='linear',use_bias=False,kernel_initializer=initializer,kernel_regularizer=keras.regularizers.l2(1e-6))(input_2)\n",
    "division = keras.layers.Lambda(lambda inputs:  tf.where(inputs[0] != 0, inputs[1]/inputs[0], inputs[1]))([l_input_1, l_input_2])#calculates empirical rt\n",
    "#max_limit = keras.layers.Lambda(lambda inputs:  tf.where(inputs[0] > 4,4*inputs[1]/inputs[0], inputs[1]))([division,division]) #limit output to max of 4 for rt\n",
    "mean = keras.layers.Lambda(lambda x: keras.backend.dot(mat,x))(division) #calculates mean r_seven in seven days\n",
    "cases = keras.layers.Multiply()([input_3,mean]) #cases for valid prediction,net output, padded with zeros at the end\n",
    "model = keras.Model(inputs=[input_1,input_2,input_3], outputs=cases)\n",
    "optimizer = keras.optimizers.SGD(1e-3)\n",
    "model.compile(optimizer='RMSprop', loss=keras.losses.MeanAbsoluteError(), metrics=['mean_absolute_error'])\n",
    "model.fit([m1,m2,a], b, epochs=500, batch_size=n_dias)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.88663197],\n",
      "       [0.92107755],\n",
      "       [0.8497143 ]], dtype=float32)] [array([[1.0407666],\n",
      "       [1.1609869],\n",
      "       [1.1275829]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "first_layer_weights = model.layers[3].get_weights()\n",
    "second_layer_weights = model.layers[2].get_weights()\n",
    "print(first_layer_weights,second_layer_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
