{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras.callbacks import History \n",
    "#using tensorflow backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_cases_per_day(fecha_sintomas,graph=False,ret=False):\n",
    "    \"\"\"\n",
    "    args: \n",
    "    -fecha_sintomas: day of beginning of symptomps for each case, can't be NaN or NaT (already processed)\n",
    "    -graph: defaults to False. if True, makes graph of new cases per day \n",
    "    -ret: defaults to False. if True, returns days-cases per day  np.array casos_por_dia\n",
    "    given the days of beginning of symptoms, processes to get np.array of cases per day and days since epidemic\n",
    "    can graph and return this vector with the defaults explained before\n",
    "    \"\"\"\n",
    "    counts = np.bincount(fecha_sintomas)\n",
    "    ultima_fecha = max(fecha_sintomas)\n",
    "    aux = range(ultima_fecha+1)\n",
    "    casos_por_dia = np.vstack((aux,counts[aux])).T #(days since inicio_epidemia x (fecha_inicio_sintomas == days))\n",
    "    if graph == True:\n",
    "        plt.xlabel(\"Dia\")\n",
    "        plt.ylabel(\"Casos\")\n",
    "        plt.axvspan(ultima_fecha-10, ultima_fecha+3, facecolor='r', alpha=0.5,label=\"últimos 10 días\")\n",
    "        plt.plot(casos_por_dia[:,0],casos_por_dia[:,1],'-ob',label=\"casos hasta dia: \"+str(ultima_fecha))\n",
    "        plt.style.use('ggplot')\n",
    "        plt.legend()\n",
    "        #plt.savefig(\"casos_por_dia_bariloche.pdf\")\n",
    "    if ret == True:\n",
    "        return casos_por_dia   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulative_cases(fecha_sintomas,graph=False,ret=False):\n",
    "    \"\"\"\n",
    "    args: \n",
    "    -fecha_sintomas: day of beginning of symptomps for each case, can't be NaN or NaT (already processed)\n",
    "    -graph: defaults to False. if True, makes graph of new cases per day \n",
    "    -ret: defaults to False. if True, returns days-cumulative cases per day np array\n",
    "    given the days of beginning of symptoms, processes to get np.array of cumulative cases per day and days since epidemic\n",
    "    can graph and return this vector with the defaults explained before\n",
    "    \"\"\"\n",
    "    ultima_fecha = max(fecha_sintomas)\n",
    "    casos_por_dia = new_cases_per_day(fecha_sintomas,ret=True)\n",
    "    casos_acumulados_por_dia = np.copy(casos_por_dia)\n",
    "    casos_acumulados_por_dia[:,1] = np.cumsum(casos_por_dia[:,1]) \n",
    "    if graph == True:\n",
    "        plt.xlabel(\"Dia\")\n",
    "        plt.ylabel(\"Casos acumulados\")\n",
    "        plt.axvspan(ultima_fecha-10, ultima_fecha+3, facecolor='r', alpha=0.5,label=\"últimos 10 días\")\n",
    "        plt.scatter(casos_acumulados_por_dia[:,0],casos_acumulados_por_dia[:,1],c='b',label=\"casos acumulados hasta dia: \"+str(ultima_fecha))\n",
    "        plt.legend()\n",
    "        plt.style.use('ggplot')\n",
    "        plt.savefig(\"casos_acumulados_bariloche.pdf\")\n",
    "    if ret == True:\n",
    "        return casos_acumulados_por_dia   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repratio_t_conv(fecha_sintomas,a,graph=False,ret=False):\n",
    "    \"\"\"\n",
    "    args: \n",
    "    -fecha_sintomas: day of beginning of symptomps for each case, can't be NaN or NaT (already processed)\n",
    "    -graph: defaults to False. if True, makes graph of rep ratio per day\n",
    "    -ret: defaults to False. if True, returns reproductive ratio per day np array of (days,r_days) and\n",
    "    the n_t vector which is used to calculate it, which is extension of new cases per day made as \n",
    "    necessary, by taking means and not linear regression. \n",
    "    given the days of beginning of symptoms, processes to get np.array of cumulative cases per day and days since epidemic\n",
    "    can graph and return this vector with the defaults explained before for days (0,lastday+4)\n",
    "    conventional version, which means no coef a,b,c,d,e. r_t valid for days >= 6. \n",
    "    \"\"\"\n",
    "    casos_por_dia = new_cases_per_day(fecha_sintomas,ret=True)\n",
    "    n_t = np.copy(casos_por_dia) #here we store data + proyection for days t+4 \n",
    "    prox_dia = max(fecha_sintomas) + 1\n",
    "    #completing the values for the rest of the values of n_t\n",
    "    aux = np.zeros(2)\n",
    "    i = 0\n",
    "    while i < 4: #completing until the day t+4 bc im gonna need it later for averaging in 7 days\n",
    "        aux[0] = prox_dia + i\n",
    "        aux[1] = np.mean(n_t[prox_dia-7:,1])\n",
    "        n_t  = np.vstack((n_t,aux)) #extending n_t up to day t+1\n",
    "        i= i +1\n",
    "    #create storage and calculate values for r_t\n",
    "    r_t = np.copy(n_t) #here we will store the rt\n",
    "    r_t = r_t.astype(float)\n",
    "    dias_aux = np.arange(0,prox_dia+3)\n",
    "    for i in dias_aux[dias_aux>=6]:\n",
    "        aux = a[0]*n_t[i-6,1] + a[1]*n_t[i-5,1] + a[2]*n_t[i-4,1] #denominator of the r_t expression\n",
    "        if(aux==0):\n",
    "            aux = 1 #the first cases in which the denominator is == 0\n",
    "        r_t[i,1] = min(((a[3]*n_t[i-1,1] + a[4]*n_t[i,1] + a[5]*n_t[i+1,1])/(aux)),4) #the rest of the days with limit value\n",
    "    if graph == True:\n",
    "        plt.style.use('ggplot')\n",
    "        plt.axvspan(prox_dia-10, prox_dia+3, facecolor='r', alpha=0.5,label=\"últimos 10 días\")\n",
    "        plt.scatter(r_t[6:prox_dia,0],r_t[6:prox_dia,1],c='b',label=r'$r_t$')\n",
    "        plt.xlabel(\"Dia\")\n",
    "        plt.ylabel(r'$r_t$',fontsize=12)\n",
    "        plt.legend()\n",
    "        plt.savefig(\"rt_raw_casos.pdf\")\n",
    "    if ret == True:\n",
    "        return n_t,r_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk_diagram(fecha_sintomas,pop,a,rep_fun=repratio_t_conv,graph=False,ret=False):\n",
    "    \"\"\"\n",
    "    args: \n",
    "    -fecha_sintomas: day of beginning of symptomps for each case, can't be NaN or NaT (already processed)\n",
    "    -pop: number of inhabitants of the region/population of interest\n",
    "    -rep_fun: function to calculate empirical reproductive ratio. defaults tp repratio_t_conv (not optimized)\n",
    "    -graph: defaults to False. if True, makes graph of risk diagram\n",
    "    -ret: defaults to False. if True, returns the components of risk diagram in two np.arrays, which are\n",
    "     the attack ratio (days>=20) as well as the rep ratio averaged over 7 days (days>=20). \n",
    "    \"\"\"\n",
    "    #we proceed to calculate what makes a risk diagram then\n",
    "    #first, we will calculate r_t average in 7 days\n",
    "    prox_dia = max(fecha_sintomas) + 1\n",
    "    n_t,r_t = rep_fun(fecha_sintomas,a,False,True)\n",
    "    r_t_seven = np.zeros(prox_dia) #real values for index>=9\n",
    "    a_t = np.zeros(prox_dia) #real values for index >= 13\n",
    "    i = 9\n",
    "    while i < prox_dia:\n",
    "        r_t_seven[i] = np.mean(r_t[i-3:i+4,1])\n",
    "        i = i+1\n",
    "    i = 13\n",
    "    while i < prox_dia:\n",
    "        a_t[i] = np.sum(n_t[i-13:i+1,1]) \n",
    "        i = i+1\n",
    "    a_t = a_t * (100000/pop)\n",
    "    if graph == True:\n",
    "        plt.plot(a_t[13:],r_t_seven[13:],'-or',markersize=5) #not at all fancy risk diagram,looks reasonable\n",
    "        plt.xlabel(r'$A_{t}^{14}$')\n",
    "        plt.ylabel(r'$R_{t}^{7}$')\n",
    "        plt.style.use('ggplot')\n",
    "        plt.title('Diagrama de riesgo Bariloche',fontsize=10)\n",
    "        plt.savefig('riskdiagram_brc.pdf')\n",
    "    if ret == True:\n",
    "        return r_t_seven,a_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_last14(casos_por_dia):\n",
    "    ac_por_dia = np.copy(casos_por_dia)\n",
    "    for i in casos_por_dia[:,0]:\n",
    "        index = np.copy(casos_por_dia[casos_por_dia[:,0]<i+1])\n",
    "        index = index[i-13<=index[:,0]]\n",
    "        index = index[:,1]\n",
    "        ac_por_dia[i,1] = np.sum(index) \n",
    "    return ac_por_dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cases(fecha_sintomas,pop,a,rep_fun=repratio_t_conv,graph=False,ret=False):\n",
    "    \"\"\"\n",
    "    args: \n",
    "    -fecha_sintomas: day of beginning of symptomps for each case, can't be NaN or NaT (already processed)\n",
    "    -pop: number of inhabitants of the region/population of interest\n",
    "    -rep_fun: function to calculate empirical reproductive ratio. defaults tp repratio_t_conv (not optimized)\n",
    "    -graph: defaults to False. if True, makes graph of risk diagram\n",
    "    -ret: defaults to False. if True, returns the predictions and cases per day\n",
    "    predicts cases per day after calculating the risk diagram, using the empirical reproductive\n",
    "    ratio given by rep_fun\n",
    "    \"\"\"\n",
    "    prox_dia = max(fecha_sintomas)+1\n",
    "    casos_por_dia = new_cases_per_day(fecha_sintomas,ret=True)\n",
    "    r_def,a_t = risk_diagram(fecha_sintomas,pop,a,rep_fun,ret=True)\n",
    "    r_def = r_def[13:]\n",
    "    a_t = a_t[13:]\n",
    "    p_t = r_def * a_t\n",
    "    valid_days = np.arange(19,prox_dia+6,1)\n",
    "    casos_por_dia = sum_last14(casos_por_dia) #gets all active cases in the last 14-days \n",
    "    if graph == True:\n",
    "        plt.style.use('ggplot')\n",
    "        plt.xlabel('Dias desde el comienzo')\n",
    "        plt.ylabel('Infectados activos en BRC')\n",
    "        plt.plot(casos_por_dia[:,0],casos_por_dia[:,1]*(100000/pop),'-ob',markersize=4,label=\"casos hasta dia: \"+str(prox_dia))\n",
    "        plt.plot(valid_days,p_t,linewidth=3,label='prediccion')\n",
    "        plt.legend()\n",
    "        #plt.savefig('9oct_predic_casos.pdf')\n",
    "    if ret == True:\n",
    "        error_global = np.linalg.norm(casos_por_dia[19:,1]-p_t[:-6])\n",
    "        return error_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_dates(df):\n",
    "    #changes fecha_inicio_sintomas according to new criteria\n",
    "    filt_df1 = (df.fecha_inicio_sintomas.isnull()) #filter fecha_inicio_sintomas = inexistant\n",
    "    df_sin_fecha = df.loc[filt_df1]\n",
    "    n_size = df_sin_fecha.shape[0]\n",
    "    df.loc[filt_df1,\"fecha_inicio_sintomas\"] = df.loc[filt_df1,\"fecha_apertura\"] - np.random.randint(0,9,n_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"casos_Bariloche.txt\",sep=\",\",quotechar='\"',\n",
    "                   parse_dates=[\"fecha_inicio_sintomas\",\"fecha_apertura\"],na_values=['']) #data loading\n",
    "df = pd.DataFrame(data) #converting to dataframe for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primer sintoma de persona confirmada:  2020-03-09 00:00:00\n",
      "ultimo sintoma de persona confirmada:  2020-10-24 00:00:00\n",
      "ultima apertura de persona confirmada:  2020-10-25 00:00:00\n"
     ]
    }
   ],
   "source": [
    "inicio_epidemia = min(df[\"fecha_inicio_sintomas\"]) #first symptoms of a person registered\n",
    "ultima_actualizacion_sintomas = max(df[\"fecha_inicio_sintomas\"]) #last day symptoms of a person registered\n",
    "ultima_actualizacion_apertura = max(df[\"fecha_apertura\"])\n",
    "df[\"fecha_inicio_sintomas\"] -= inicio_epidemia #correcting by inicio_epidemia \n",
    "df[\"fecha_apertura\"] -= inicio_epidemia #correcting by inicio_epidemia\n",
    "df.fecha_inicio_sintomas = df.fecha_inicio_sintomas.dt.days #change to int, ditch days \n",
    "df.fecha_apertura = df.fecha_apertura.dt.days #change to int, ditch days\n",
    "change_dates(df) #replaces non existing fecha_inicio_sintomas acc to new criteria\n",
    "print(\"primer sintoma de persona confirmada: \",inicio_epidemia)\n",
    "print(\"ultimo sintoma de persona confirmada: \",ultima_actualizacion_sintomas)\n",
    "print(\"ultima apertura de persona confirmada: \",ultima_actualizacion_apertura)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha_sintomas = df.fecha_inicio_sintomas.to_numpy() #numpy array of fecha_inicio_sintomas\n",
    "fecha_apertura = df.fecha_apertura.to_numpy() #numpy array of fecha_apertura\n",
    "fecha_sintomas = fecha_sintomas.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros(6) + 1\n",
    "pop = 100000\n",
    "rep_fun = repratio_t_conv\n",
    "r_def,a_t = risk_diagram(fecha_sintomas,pop,a,rep_fun,ret=True)\n",
    "a_t = a_t[13:]\n",
    "a_t[a_t.shape[0]-7:] = 0\n",
    "a = np.zeros(a_t.shape[0]+10)\n",
    "a[:a_t.shape[0]] = a_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "casos_por_dia = new_cases_per_day(fecha_sintomas,ret=True)\n",
    "casos_por_dia = sum_last14(casos_por_dia)\n",
    "casos_por_dia = casos_por_dia[20:,1]\n",
    "b = np.zeros(a_t.shape[0]+10)\n",
    "b[:casos_por_dia.shape[0]] = casos_por_dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "casos_por_dia = new_cases_per_day(fecha_sintomas,ret=True)\n",
    "n_t = np.copy(casos_por_dia)\n",
    "prox_dia = max(fecha_sintomas) + 1\n",
    "#completing the values for the rest of the values of n_t\n",
    "aux = np.zeros(2)\n",
    "i = 0\n",
    "while i < 4: #completing until the day t+4 bc im gonna need it later for averaging in 7 days\n",
    "    aux[0] = prox_dia + i\n",
    "    aux[1] = np.mean(n_t[prox_dia-7:,1])\n",
    "    n_t  = np.vstack((n_t,aux)) #extending n_t up to day t+1\n",
    "    i= i +1\n",
    "dias = np.copy(n_t[:,0]).astype(int)\n",
    "dias = dias[:-1]\n",
    "m1 = np.zeros((dias[dias>=6].shape[0],3)) #denominator of r7 expression\n",
    "m2 = np.zeros((dias[dias>=6].shape[0],3)) #numerator of r7 expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dias[dias>=6]:\n",
    "    m1[i-6,:] = n_t[i-6:i-3,1]\n",
    "    m2[i-6,:] = n_t[i-1:i+2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dias = m1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_matrix(shape):\n",
    "    n_dias = shape\n",
    "    m = np.zeros((n_dias,n_dias))\n",
    "    i = 0\n",
    "    while i < n_dias - 7:\n",
    "        m[i,i:i+7] = 1/7\n",
    "        i = i + 1\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpyA = my_matrix(n_dias)\n",
    "numpyA = keras.backend.variable(numpyA)\n",
    "mat = numpyA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "227/227 [==============================] - 0s 275us/step - loss: 28072.1113 - MSE: 28072.1133\n",
      "Epoch 2/10\n",
      "227/227 [==============================] - 0s 0us/step - loss: nan - MSE: nan\n",
      "Epoch 3/10\n",
      "227/227 [==============================] - 0s 35us/step - loss: nan - MSE: nan\n",
      "Epoch 4/10\n",
      "227/227 [==============================] - 0s 35us/step - loss: nan - MSE: nan\n",
      "Epoch 5/10\n",
      "227/227 [==============================] - 0s 0us/step - loss: nan - MSE: nan\n",
      "Epoch 6/10\n",
      "227/227 [==============================] - 0s 0us/step - loss: nan - MSE: nan\n",
      "Epoch 7/10\n",
      "227/227 [==============================] - 0s 0us/step - loss: nan - MSE: nan\n",
      "Epoch 8/10\n",
      "227/227 [==============================] - 0s 0us/step - loss: nan - MSE: nan\n",
      "Epoch 9/10\n",
      "227/227 [==============================] - 0s 35us/step - loss: nan - MSE: nan\n",
      "Epoch 10/10\n",
      "227/227 [==============================] - 0s 0us/step - loss: nan - MSE: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2668d7cab08>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_1 = keras.layers.Input(shape=(3,))\n",
    "input_2 = keras.layers.Input(shape=(3,))\n",
    "input_3 = keras.layers.Input(shape=(1,))\n",
    "initializer = keras.initializers.Ones() #the vector of weights a\n",
    "l_input_1 = keras.layers.Dense(1,activation='linear',use_bias=False,kernel_initializer=initializer)(input_1)\n",
    "l_input_2 = keras.layers.Dense(1,activation='linear',use_bias=False,kernel_initializer=initializer)(input_2)\n",
    "division = keras.layers.Lambda(lambda inputs:  tf.where(inputs[0] != 0, inputs[1]/inputs[0], inputs[1]))([l_input_1, l_input_2])#calculates empirical rt\n",
    "max_limit = keras.layers.Lambda(lambda inputs:  tf.where(inputs[0] > 4,4*inputs[1]/inputs[0], inputs[1]))([division,division]) #limit output to max of 4 for rt\n",
    "mean = keras.layers.Lambda(lambda x: keras.backend.dot(mat,x))(max_limit) #calculates mean r_seven in seven days\n",
    "cases = keras.layers.Multiply()([input_3,mean]) #cases for valid prediction,net output, padded with zeros at the end\n",
    "model = keras.Model(inputs=[input_1,input_2,input_3], outputs=cases)\n",
    "model.compile(optimizer='sgd', loss=keras.losses.MSE, metrics=['MSE'])\n",
    "model.fit([m1,m2,a], b, epochs=10, batch_size=n_dias, verbose=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
