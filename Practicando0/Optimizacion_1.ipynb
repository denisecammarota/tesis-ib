{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras.callbacks import History \n",
    "#using tensorflow backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_cases_per_day(fecha_sintomas,graph=False,ret=False):\n",
    "    \"\"\"\n",
    "    args: \n",
    "    -fecha_sintomas: day of beginning of symptomps for each case, can't be NaN or NaT (already processed)\n",
    "    -graph: defaults to False. if True, makes graph of new cases per day \n",
    "    -ret: defaults to False. if True, returns days-cases per day  np.array casos_por_dia\n",
    "    given the days of beginning of symptoms, processes to get np.array of cases per day and days since epidemic\n",
    "    can graph and return this vector with the defaults explained before\n",
    "    \"\"\"\n",
    "    counts = np.bincount(fecha_sintomas)\n",
    "    ultima_fecha = max(fecha_sintomas)\n",
    "    aux = range(ultima_fecha+1)\n",
    "    casos_por_dia = np.vstack((aux,counts[aux])).T #(days since inicio_epidemia x (fecha_inicio_sintomas == days))\n",
    "    if graph == True:\n",
    "        plt.xlabel(\"Dia\")\n",
    "        plt.ylabel(\"Casos\")\n",
    "        plt.axvspan(ultima_fecha-10, ultima_fecha+3, facecolor='r', alpha=0.5,label=\"últimos 10 días\")\n",
    "        plt.plot(casos_por_dia[:,0],casos_por_dia[:,1],'-ob',label=\"casos hasta dia: \"+str(ultima_fecha))\n",
    "        plt.style.use('ggplot')\n",
    "        plt.legend()\n",
    "        #plt.savefig(\"casos_por_dia_bariloche.pdf\")\n",
    "    if ret == True:\n",
    "        return casos_por_dia   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulative_cases(fecha_sintomas,graph=False,ret=False):\n",
    "    \"\"\"\n",
    "    args: \n",
    "    -fecha_sintomas: day of beginning of symptomps for each case, can't be NaN or NaT (already processed)\n",
    "    -graph: defaults to False. if True, makes graph of new cases per day \n",
    "    -ret: defaults to False. if True, returns days-cumulative cases per day np array\n",
    "    given the days of beginning of symptoms, processes to get np.array of cumulative cases per day and days since epidemic\n",
    "    can graph and return this vector with the defaults explained before\n",
    "    \"\"\"\n",
    "    ultima_fecha = max(fecha_sintomas)\n",
    "    casos_por_dia = new_cases_per_day(fecha_sintomas,ret=True)\n",
    "    casos_acumulados_por_dia = np.copy(casos_por_dia)\n",
    "    casos_acumulados_por_dia[:,1] = np.cumsum(casos_por_dia[:,1]) \n",
    "    if graph == True:\n",
    "        plt.xlabel(\"Dia\")\n",
    "        plt.ylabel(\"Casos acumulados\")\n",
    "        plt.axvspan(ultima_fecha-10, ultima_fecha+3, facecolor='r', alpha=0.5,label=\"últimos 10 días\")\n",
    "        plt.scatter(casos_acumulados_por_dia[:,0],casos_acumulados_por_dia[:,1],c='b',label=\"casos acumulados hasta dia: \"+str(ultima_fecha))\n",
    "        plt.legend()\n",
    "        plt.style.use('ggplot')\n",
    "        plt.savefig(\"casos_acumulados_bariloche.pdf\")\n",
    "    if ret == True:\n",
    "        return casos_acumulados_por_dia   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repratio_t_conv(fecha_sintomas,a,graph=False,ret=False):\n",
    "    \"\"\"\n",
    "    args: \n",
    "    -fecha_sintomas: day of beginning of symptomps for each case, can't be NaN or NaT (already processed)\n",
    "    -graph: defaults to False. if True, makes graph of rep ratio per day\n",
    "    -ret: defaults to False. if True, returns reproductive ratio per day np array of (days,r_days) and\n",
    "    the n_t vector which is used to calculate it, which is extension of new cases per day made as \n",
    "    necessary, by taking means and not linear regression. \n",
    "    given the days of beginning of symptoms, processes to get np.array of cumulative cases per day and days since epidemic\n",
    "    can graph and return this vector with the defaults explained before for days (0,lastday+4)\n",
    "    conventional version, which means no coef a,b,c,d,e. r_t valid for days >= 6. \n",
    "    \"\"\"\n",
    "    casos_por_dia = new_cases_per_day(fecha_sintomas,ret=True)\n",
    "    n_t = np.copy(casos_por_dia) #here we store data + proyection for days t+4 \n",
    "    prox_dia = max(fecha_sintomas) + 1\n",
    "    #completing the values for the rest of the values of n_t\n",
    "    aux = np.zeros(2)\n",
    "    i = 0\n",
    "    while i < 4: #completing until the day t+4 bc im gonna need it later for averaging in 7 days\n",
    "        aux[0] = prox_dia + i\n",
    "        aux[1] = np.mean(n_t[prox_dia-7:,1])\n",
    "        n_t  = np.vstack((n_t,aux)) #extending n_t up to day t+1\n",
    "        i= i +1\n",
    "    #create storage and calculate values for r_t\n",
    "    r_t = np.copy(n_t) #here we will store the rt\n",
    "    r_t = r_t.astype(float)\n",
    "    dias_aux = np.arange(0,prox_dia+3)\n",
    "    for i in dias_aux[dias_aux>=6]:\n",
    "        aux = a[0]*n_t[i-6,1] + a[1]*n_t[i-5,1] + a[2]*n_t[i-4,1] #denominator of the r_t expression\n",
    "        if(aux==0):\n",
    "            aux = 1 #the first cases in which the denominator is == 0\n",
    "        r_t[i,1] = min(((a[3]*n_t[i-1,1] + a[4]*n_t[i,1] + a[5]*n_t[i+1,1])/(aux)),4) #the rest of the days with limit value\n",
    "    if graph == True:\n",
    "        plt.style.use('ggplot')\n",
    "        plt.axvspan(prox_dia-10, prox_dia+3, facecolor='r', alpha=0.5,label=\"últimos 10 días\")\n",
    "        plt.scatter(r_t[6:prox_dia,0],r_t[6:prox_dia,1],c='b',label=r'$r_t$')\n",
    "        plt.xlabel(\"Dia\")\n",
    "        plt.ylabel(r'$r_t$',fontsize=12)\n",
    "        plt.legend()\n",
    "        plt.savefig(\"rt_raw_casos.pdf\")\n",
    "    if ret == True:\n",
    "        return n_t,r_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk_diagram(fecha_sintomas,pop,a,rep_fun=repratio_t_conv,graph=False,ret=False):\n",
    "    \"\"\"\n",
    "    args: \n",
    "    -fecha_sintomas: day of beginning of symptomps for each case, can't be NaN or NaT (already processed)\n",
    "    -pop: number of inhabitants of the region/population of interest\n",
    "    -rep_fun: function to calculate empirical reproductive ratio. defaults tp repratio_t_conv (not optimized)\n",
    "    -graph: defaults to False. if True, makes graph of risk diagram\n",
    "    -ret: defaults to False. if True, returns the components of risk diagram in two np.arrays, which are\n",
    "     the attack ratio (days>=20) as well as the rep ratio averaged over 7 days (days>=20). \n",
    "    \"\"\"\n",
    "    #we proceed to calculate what makes a risk diagram then\n",
    "    #first, we will calculate r_t average in 7 days\n",
    "    prox_dia = max(fecha_sintomas) + 1\n",
    "    n_t,r_t = rep_fun(fecha_sintomas,a,False,True)\n",
    "    r_t_seven = np.zeros(prox_dia) #real values for index>=9\n",
    "    a_t = np.zeros(prox_dia) #real values for index >= 13\n",
    "    i = 9\n",
    "    while i < prox_dia:\n",
    "        r_t_seven[i] = np.mean(r_t[i-3:i+4,1])\n",
    "        i = i+1\n",
    "    i = 13\n",
    "    while i < prox_dia:\n",
    "        a_t[i] = np.sum(n_t[i-13:i+1,1]) \n",
    "        i = i+1\n",
    "    a_t = a_t * (100000/pop)\n",
    "    if graph == True:\n",
    "        plt.plot(a_t[13:],r_t_seven[13:],'-or',markersize=5) #not at all fancy risk diagram,looks reasonable\n",
    "        plt.xlabel(r'$A_{t}^{14}$')\n",
    "        plt.ylabel(r'$R_{t}^{7}$')\n",
    "        plt.style.use('ggplot')\n",
    "        plt.title('Diagrama de riesgo Bariloche',fontsize=10)\n",
    "        plt.savefig('riskdiagram_brc.pdf')\n",
    "    if ret == True:\n",
    "        return r_t_seven,a_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_last14(casos_por_dia):\n",
    "    ac_por_dia = np.copy(casos_por_dia)\n",
    "    for i in casos_por_dia[:,0]:\n",
    "        index = np.copy(casos_por_dia[casos_por_dia[:,0]<i+1])\n",
    "        index = index[i-13<=index[:,0]]\n",
    "        index = index[:,1]\n",
    "        ac_por_dia[i,1] = np.sum(index) \n",
    "    return ac_por_dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cases(fecha_sintomas,pop,a,rep_fun=repratio_t_conv,graph=False,ret=False):\n",
    "    \"\"\"\n",
    "    args: \n",
    "    -fecha_sintomas: day of beginning of symptomps for each case, can't be NaN or NaT (already processed)\n",
    "    -pop: number of inhabitants of the region/population of interest\n",
    "    -rep_fun: function to calculate empirical reproductive ratio. defaults tp repratio_t_conv (not optimized)\n",
    "    -graph: defaults to False. if True, makes graph of risk diagram\n",
    "    -ret: defaults to False. if True, returns the predictions and cases per day\n",
    "    predicts cases per day after calculating the risk diagram, using the empirical reproductive\n",
    "    ratio given by rep_fun\n",
    "    \"\"\"\n",
    "    prox_dia = max(fecha_sintomas)+1\n",
    "    casos_por_dia = new_cases_per_day(fecha_sintomas,ret=True)\n",
    "    r_def,a_t = risk_diagram(fecha_sintomas,pop,a,rep_fun,ret=True)\n",
    "    r_def = r_def[13:]\n",
    "    a_t = a_t[13:]\n",
    "    p_t = r_def * a_t\n",
    "    valid_days = np.arange(19,prox_dia+6,1)\n",
    "    casos_por_dia = sum_last14(casos_por_dia) #gets all active cases in the last 14-days \n",
    "    if graph == True:\n",
    "        plt.style.use('ggplot')\n",
    "        plt.xlabel('Dias desde el comienzo')\n",
    "        plt.ylabel('Infectados activos en BRC')\n",
    "        plt.plot(casos_por_dia[:,0],casos_por_dia[:,1]*(100000/pop),'-ob',markersize=4,label=\"casos hasta dia: \"+str(prox_dia))\n",
    "        plt.plot(valid_days,p_t,linewidth=3,label='prediccion')\n",
    "        plt.legend()\n",
    "        #plt.savefig('9oct_predic_casos.pdf')\n",
    "    if ret == True:\n",
    "        error_global = np.linalg.norm(casos_por_dia[19:,1]-p_t[:-6])\n",
    "        return error_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_dates(df):\n",
    "    #changes fecha_inicio_sintomas according to new criteria\n",
    "    filt_df1 = (df.fecha_inicio_sintomas.isnull()) #filter fecha_inicio_sintomas = inexistant\n",
    "    df_sin_fecha = df.loc[filt_df1]\n",
    "    n_size = df_sin_fecha.shape[0]\n",
    "    df.loc[filt_df1,\"fecha_inicio_sintomas\"] = df.loc[filt_df1,\"fecha_apertura\"] - np.random.randint(0,9,n_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"casos_Bariloche.txt\",sep=\",\",quotechar='\"',\n",
    "                   parse_dates=[\"fecha_inicio_sintomas\",\"fecha_apertura\"],na_values=['']) #data loading\n",
    "df = pd.DataFrame(data) #converting to dataframe for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primer sintoma de persona confirmada:  2020-03-09 00:00:00\n",
      "ultimo sintoma de persona confirmada:  2020-10-24 00:00:00\n",
      "ultima apertura de persona confirmada:  2020-10-25 00:00:00\n"
     ]
    }
   ],
   "source": [
    "inicio_epidemia = min(df[\"fecha_inicio_sintomas\"]) #first symptoms of a person registered\n",
    "ultima_actualizacion_sintomas = max(df[\"fecha_inicio_sintomas\"]) #last day symptoms of a person registered\n",
    "ultima_actualizacion_apertura = max(df[\"fecha_apertura\"])\n",
    "df[\"fecha_inicio_sintomas\"] -= inicio_epidemia #correcting by inicio_epidemia \n",
    "df[\"fecha_apertura\"] -= inicio_epidemia #correcting by inicio_epidemia\n",
    "df.fecha_inicio_sintomas = df.fecha_inicio_sintomas.dt.days #change to int, ditch days \n",
    "df.fecha_apertura = df.fecha_apertura.dt.days #change to int, ditch days\n",
    "change_dates(df) #replaces non existing fecha_inicio_sintomas acc to new criteria\n",
    "print(\"primer sintoma de persona confirmada: \",inicio_epidemia)\n",
    "print(\"ultimo sintoma de persona confirmada: \",ultima_actualizacion_sintomas)\n",
    "print(\"ultima apertura de persona confirmada: \",ultima_actualizacion_apertura)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha_sintomas = df.fecha_inicio_sintomas.to_numpy() #numpy array of fecha_inicio_sintomas\n",
    "fecha_apertura = df.fecha_apertura.to_numpy() #numpy array of fecha_apertura\n",
    "fecha_sintomas = fecha_sintomas.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "casos_por_dia = new_cases_per_day(fecha_sintomas,ret=True)\n",
    "n_t = np.copy(casos_por_dia)\n",
    "dias = np.copy(casos_por_dia[:,0])\n",
    "m1 = np.zeros((dias[dias>=6].shape[0],3)) #denominator of r7 expression\n",
    "m2 = np.zeros((dias[dias>=6].shape[0],3)) #numerator of r7 expression\n",
    "prox_dia = max(fecha_sintomas) + 1\n",
    "#completing the values for the rest of the values of n_t\n",
    "aux = np.zeros(2)\n",
    "i = 0\n",
    "while i < 4: #completing until the day t+4 bc im gonna need it later for averaging in 7 days\n",
    "    aux[0] = prox_dia + i\n",
    "    aux[1] = np.mean(n_t[prox_dia-7:,1])\n",
    "    n_t  = np.vstack((n_t,aux)) #extending n_t up to day t+1\n",
    "    i= i +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dias[dias>=6]:\n",
    "    m1[i-6,:] = n_t[i-6:i-3,1]\n",
    "    m2[i-6,:] = n_t[i-1:i+2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            3           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            3           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 6\n",
      "Trainable params: 6\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        ],\n",
       "       [4.        ],\n",
       "       [4.        ],\n",
       "       [4.        ],\n",
       "       [4.        ],\n",
       "       [6.        ],\n",
       "       [8.        ],\n",
       "       [6.        ],\n",
       "       [4.        ],\n",
       "       [1.        ],\n",
       "       [0.6666667 ],\n",
       "       [0.5       ],\n",
       "       [0.6666667 ],\n",
       "       [1.2       ],\n",
       "       [2.        ],\n",
       "       [2.75      ],\n",
       "       [2.        ],\n",
       "       [1.25      ],\n",
       "       [0.6666667 ],\n",
       "       [1.        ],\n",
       "       [0.8181818 ],\n",
       "       [1.25      ],\n",
       "       [1.8       ],\n",
       "       [3.5       ],\n",
       "       [1.625     ],\n",
       "       [1.2222222 ],\n",
       "       [1.3       ],\n",
       "       [1.7777778 ],\n",
       "       [1.0714285 ],\n",
       "       [0.84615386],\n",
       "       [0.54545456],\n",
       "       [0.46153846],\n",
       "       [0.1875    ],\n",
       "       [0.2       ],\n",
       "       [0.45454547],\n",
       "       [0.8333333 ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.4       ],\n",
       "       [0.6       ],\n",
       "       [0.5       ],\n",
       "       [1.        ],\n",
       "       [1.3333334 ],\n",
       "       [2.5       ],\n",
       "       [2.        ],\n",
       "       [1.6666666 ],\n",
       "       [1.3333334 ],\n",
       "       [0.75      ],\n",
       "       [1.        ],\n",
       "       [0.6666667 ],\n",
       "       [1.6       ],\n",
       "       [2.25      ],\n",
       "       [4.6666665 ],\n",
       "       [3.        ],\n",
       "       [3.5       ],\n",
       "       [1.375     ],\n",
       "       [1.3333334 ],\n",
       "       [1.0714285 ],\n",
       "       [1.        ],\n",
       "       [0.78571427],\n",
       "       [0.54545456],\n",
       "       [0.5833333 ],\n",
       "       [0.4       ],\n",
       "       [0.6       ],\n",
       "       [0.8181818 ],\n",
       "       [1.1666666 ],\n",
       "       [0.5714286 ],\n",
       "       [0.6666667 ],\n",
       "       [0.6666667 ],\n",
       "       [0.8888889 ],\n",
       "       [1.        ],\n",
       "       [1.5       ],\n",
       "       [1.        ],\n",
       "       [0.33333334],\n",
       "       [0.5       ],\n",
       "       [1.        ],\n",
       "       [1.6666666 ],\n",
       "       [1.75      ],\n",
       "       [2.5       ],\n",
       "       [1.        ],\n",
       "       [0.5714286 ],\n",
       "       [0.6       ],\n",
       "       [1.        ],\n",
       "       [1.8       ],\n",
       "       [2.        ],\n",
       "       [3.25      ],\n",
       "       [2.6666667 ],\n",
       "       [3.        ],\n",
       "       [1.6666666 ],\n",
       "       [1.625     ],\n",
       "       [0.6923077 ],\n",
       "       [0.8125    ],\n",
       "       [0.85714287],\n",
       "       [1.4       ],\n",
       "       [1.4615384 ],\n",
       "       [1.7777778 ],\n",
       "       [1.1538461 ],\n",
       "       [1.        ],\n",
       "       [1.2380953 ],\n",
       "       [1.3157895 ],\n",
       "       [1.3125    ],\n",
       "       [0.8       ],\n",
       "       [0.5       ],\n",
       "       [0.3846154 ],\n",
       "       [0.48      ],\n",
       "       [0.8095238 ],\n",
       "       [1.25      ],\n",
       "       [1.7777778 ],\n",
       "       [1.2       ],\n",
       "       [1.25      ],\n",
       "       [0.8235294 ],\n",
       "       [1.1333333 ],\n",
       "       [1.25      ],\n",
       "       [1.8333334 ],\n",
       "       [2.2       ],\n",
       "       [2.142857  ],\n",
       "       [1.7058823 ],\n",
       "       [1.05      ],\n",
       "       [1.0909091 ],\n",
       "       [0.72727275],\n",
       "       [0.76666665],\n",
       "       [0.7241379 ],\n",
       "       [1.2380953 ],\n",
       "       [1.0833334 ],\n",
       "       [1.375     ],\n",
       "       [1.3913044 ],\n",
       "       [1.7619047 ],\n",
       "       [1.3846154 ],\n",
       "       [1.6538461 ],\n",
       "       [1.5757576 ],\n",
       "       [2.        ],\n",
       "       [2.2162163 ],\n",
       "       [3.0277777 ],\n",
       "       [3.2325583 ],\n",
       "       [2.8269231 ],\n",
       "       [2.421875  ],\n",
       "       [1.902439  ],\n",
       "       [1.7431192 ],\n",
       "       [1.3741007 ],\n",
       "       [1.2653061 ],\n",
       "       [1.0451612 ],\n",
       "       [0.86538464],\n",
       "       [0.63684213],\n",
       "       [0.5183246 ],\n",
       "       [0.516129  ],\n",
       "       [0.5493827 ],\n",
       "       [0.6296296 ],\n",
       "       [0.6446281 ],\n",
       "       [0.72727275],\n",
       "       [0.625     ],\n",
       "       [0.6853933 ],\n",
       "       [0.69411767],\n",
       "       [0.78205127],\n",
       "       [0.9305556 ],\n",
       "       [1.1333333 ],\n",
       "       [1.0655738 ],\n",
       "       [1.0169492 ],\n",
       "       [0.91803277],\n",
       "       [1.0447761 ],\n",
       "       [1.117647  ],\n",
       "       [1.2       ],\n",
       "       [1.0833334 ],\n",
       "       [1.0535715 ],\n",
       "       [0.9714286 ],\n",
       "       [0.9736842 ],\n",
       "       [1.0384616 ],\n",
       "       [1.2153846 ],\n",
       "       [1.4915254 ],\n",
       "       [1.4117647 ],\n",
       "       [1.472973  ],\n",
       "       [1.5061729 ],\n",
       "       [1.6835443 ],\n",
       "       [1.625     ],\n",
       "       [1.59375   ],\n",
       "       [1.6513761 ],\n",
       "       [1.5163934 ],\n",
       "       [1.5789474 ],\n",
       "       [1.5384616 ],\n",
       "       [1.6666666 ],\n",
       "       [1.2722223 ],\n",
       "       [1.1405406 ],\n",
       "       [0.86190474],\n",
       "       [0.79545456],\n",
       "       [0.5568628 ],\n",
       "       [0.5371179 ],\n",
       "       [0.5829384 ],\n",
       "       [0.6906077 ],\n",
       "       [0.6628571 ],\n",
       "       [0.8028169 ],\n",
       "       [1.0894309 ],\n",
       "       [1.2439024 ],\n",
       "       [1.152     ],\n",
       "       [1.0948275 ],\n",
       "       [0.9385965 ],\n",
       "       [0.7910448 ],\n",
       "       [0.6535948 ],\n",
       "       [0.7916667 ],\n",
       "       [0.88188976],\n",
       "       [1.1401869 ],\n",
       "       [1.0849056 ],\n",
       "       [1.37      ],\n",
       "       [1.2017543 ],\n",
       "       [1.4642857 ],\n",
       "       [1.3770492 ],\n",
       "       [1.6521739 ],\n",
       "       [1.3284671 ],\n",
       "       [1.2627738 ],\n",
       "       [1.        ],\n",
       "       [1.0119047 ],\n",
       "       [0.92105263],\n",
       "       [0.978022  ],\n",
       "       [1.0693642 ],\n",
       "       [1.0853659 ],\n",
       "       [0.9647059 ],\n",
       "       [0.88      ],\n",
       "       [0.91573036],\n",
       "       [0.972973  ],\n",
       "       [0.9044944 ],\n",
       "       [0.7621951 ],\n",
       "       [0.53896105],\n",
       "       [0.36196318],\n",
       "       [0.25555557],\n",
       "       [0.16149068],\n",
       "       [0.2685714 ]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_1 = keras.layers.Input(shape=(3,))\n",
    "input_2 = keras.layers.Input(shape=(3,))\n",
    "initializer = keras.initializers.Ones() #the vector of weights a \n",
    "l_input_1 = keras.layers.Dense(1,activation='linear',use_bias=False,kernel_initializer=initializer)(input_1)\n",
    "l_input_2 = keras.layers.Dense(1,activation='linear',use_bias=False,kernel_initializer=initializer)(input_2)\n",
    "division = keras.layers.Lambda(lambda inputs:  tf.where(inputs[0] != 0, inputs[1]/inputs[0], 4.0))([l_input_1, l_input_2]) #calculates empirical r7\n",
    "model = keras.Model(inputs=[input_1,input_2], outputs=division)\n",
    "model.summary()\n",
    "model.predict([m1,m2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
